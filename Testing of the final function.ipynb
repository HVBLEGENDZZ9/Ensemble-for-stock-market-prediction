{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "918dde54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b825b66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_scores_comparator(add_time,add_posts,bert,stock,l):\n",
    "    '''\n",
    "    Args:\n",
    "    add_time: address of the file that has time series data of the stock\n",
    "    add_posts: address of the  file that has all the posts of the stock, labelled as spam or not spam\n",
    "    bert: address of the bert sentiment analysis model\n",
    "    stock: name of the stock\n",
    "    l: list of all models that the target model's results have to be compared to\n",
    "\n",
    "    Returns:\n",
    "    A pandas dataframe containing the MAEs and MSEs of all the models\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import tensorflow_hub as hub\n",
    "    import tensorflow_text as text\n",
    "    df_stock = pd.read_csv(add_time,\n",
    "                     parse_dates = [\"Date\"],\n",
    "                     index_col = [\"Date\"])\n",
    "    df_posts = pd.read_excel(add_posts)\n",
    "    # removing the unnecessary columns\n",
    "    df_posts.drop([\"Unnamed: 0\"], axis=1,inplace=True)\n",
    "    # removing spam posts\n",
    "    df_posts = df_posts[df_posts.Spam==0.0]\n",
    "    df_posts.drop([\"Spam\"],axis=1,inplace=True)\n",
    "    # sliding a window of 7 days and adding all the TIs\n",
    "    from stock_helper import prepare_data\n",
    "    x,y = prepare_data(df_stock)\n",
    "    # slicing the data\n",
    "    final_x = x[np.datetime64(\"2021-11-13\"):]\n",
    "    final_y = y[np.datetime64(\"2021-11-13\"):]\n",
    "    # reversing the posts data\n",
    "    df_posts = df_posts[::-1]\n",
    "    final_posts = df_posts[7:]\n",
    "    # loading the sentiment analysis model\n",
    "    sent_model = tf.keras.models.load_model(bert)\n",
    "    # removing duplicates from the data\n",
    "    final_posts.drop_duplicates(subset=['Messages'])\n",
    "    # calculating the sentiments score\n",
    "    sentiments = []\n",
    "    prev = np.datetime64(\"2015-11-12 21:31:26\")\n",
    "    for i in final_y.index:\n",
    "        total=0\n",
    "        cnt=0\n",
    "        for j in final_posts.itertuples():\n",
    "            _,msg,time = j\n",
    "            if np.datetime64(time)<np.datetime64(i) and np.datetime64(time)>prev:\n",
    "                total += tf.squeeze(sent_model.predict([msg])).numpy()\n",
    "                cnt+=1\n",
    "        prev = np.datetime64(i)\n",
    "        if(cnt==0):\n",
    "            sentiments.append(0)\n",
    "        else:\n",
    "            sentiments.append(total/cnt)\n",
    "    # getting indices where sentiments score is 0\n",
    "    zero_index = []\n",
    "    for i,j in enumerate(sentiments):\n",
    "        if(j==0):\n",
    "            zero_index.append(i)\n",
    "    # removing all the zero values indices\n",
    "    sentiments = np.delete(sentiments,zero_index)\n",
    "    final_x_zeros = final_x.copy()\n",
    "    final_y_zeros = final_y.copy()\n",
    "    final_y_zeros = final_y_zeros.to_frame()\n",
    "    final_x_zeros['removal_assist'] = np.arange(0,len(final_x),1)\n",
    "    final_y_zeros['removal_assist'] = np.arange(0,len(final_x),1)\n",
    "    final_y_zeros = final_y_zeros[final_y_zeros.removal_assist.isin(zero_index)==False]\n",
    "    final_x_zeros = final_x_zeros[final_x_zeros.removal_assist.isin(zero_index)==False]\n",
    "    # removing the added helper column\n",
    "    final_x_zeros.drop([\"removal_assist\"], axis=1,inplace=True)\n",
    "    final_y_zeros.drop([\"removal_assist\"], axis=1, inplace=True)\n",
    "    # preparing the scaled data\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    mms = MinMaxScaler()\n",
    "    final_x_zeros_scaled = mms.fit_transform(final_x_zeros)\n",
    "    max_val = final_y_zeros.max()\n",
    "    final_y_zeros_scaled = final_y_zeros/max_val\n",
    "    # loading the nbeats model for the given stock\n",
    "    model_nbeats = tf.keras.models.load_model(\"nbeats_\" + stock)\n",
    "    # making predictions and building the final dataframe \n",
    "    preds = tf.squeeze(model_nbeats.predict(final_x_zeros)).numpy()\n",
    "    final_df = pd.DataFrame({\"Predictions\": preds,\n",
    "                        \"Sentiments\":sentiments})\n",
    "    # building and training the target model\n",
    "    tf.random.set_seed(42)\n",
    "    inputs = tf.keras.Input(shape=(2))\n",
    "    x = tf.keras.layers.Dense(8, activation=\"selu\", kernel_initializer=\"lecun_normal\")(inputs)\n",
    "    x = tf.keras.layers.Dense(8, activation=\"selu\", kernel_initializer=\"lecun_normal\")(x)\n",
    "    x = tf.keras.layers.Dense(8, activation=\"selu\", kernel_initializer=\"lecun_normal\")(x)\n",
    "    outputs = tf.keras.layers.Dense(1)(x)\n",
    "    model = tf.keras.models.Model(inputs=inputs,outputs=outputs)\n",
    "    \n",
    "    k = int(np.round(len(final_x_zeros)*0.8))\n",
    "    xtrain,ytrain,xtest,ytest = final_df[:k],final_y_zeros[:k],final_df[k:],final_y_zeros[k:]\n",
    "    \n",
    "    model.compile(loss = \"mae\", optimizer = tf.keras.optimizers.Adam(), metrics=[\"mae\",\"mse\"])\n",
    "    history = model.fit(xtrain,ytrain,\n",
    "                        epochs = 1000,\n",
    "                        validation_data=(xtest,ytest), \n",
    "                        verbose=0,\n",
    "                        callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", \n",
    "                                                                patience=200, \n",
    "                                                                restore_best_weights=True),\n",
    "                              tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", \n",
    "                                                                   patience=100, \n",
    "                                                                   verbose=1)])\n",
    "    target_result = model.evaluate(xtest,ytest)\n",
    "    dict_res = {\n",
    "        \"Target_model\":[target_result[1]]\n",
    "    }\n",
    "    df = pd.DataFrame(dict_res)\n",
    "    frames = []\n",
    "    frames.append(df)\n",
    "    # getting the results of all the other models\n",
    "    scaled_models = [\"GRU\",\"LSTM\"]\n",
    "    for i in l:\n",
    "        name = i + \"_\" + stock\n",
    "        model = tf.keras.models.load_model(name)\n",
    "        if i in scaled_models:\n",
    "            print(\"scaled_model\")\n",
    "            preds = tf.squeeze(model.predict(final_x_zeros_scaled[k:])).numpy()\n",
    "            preds = preds*max_val.values[0]\n",
    "            print(preds)\n",
    "            result = sum(abs(preds-tf.squeeze(final_y_zeros[k:].to_numpy()).numpy()))\n",
    "            print(tf.squeeze(final_y_zeros[k:].to_numpy()).numpy())\n",
    "            dict_res = {\n",
    "             i:[result]\n",
    "            }\n",
    "            df = pd.DataFrame(dict_res)\n",
    "            frames.append(df)\n",
    "        else:\n",
    "            result = model.evaluate(final_x_zeros[k:], final_y_zeros[k:])\n",
    "            dict_res = {\n",
    "             i:[result[1]]\n",
    "            }\n",
    "            df = pd.DataFrame(dict_res)\n",
    "            frames.append(df)\n",
    "    return pd.concat(frames, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed82b248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00258: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 26.9820 - mae: 26.9820 - mse: 1271.0349\n",
      "1/1 [==============================] - 2s 2s/step - loss: 48.7430 - mae: 48.7430 - mse: 2729.7170\n",
      "scaled_model\n",
      "[1135.9811 1127.7804 1116.2896 1110.5485 1146.7969 1164.5603 1167.7561\n",
      " 1175.9675 1182.9775 1194.5582 1203.2809 1206.635  1209.3304]\n",
      "[1109.1  1088.35 1084.65 1085.55 1167.35 1167.5  1166.6  1176.3  1183.\n",
      " 1219.6  1222.35 1248.35 1254.45]\n",
      "scaled_model\n",
      "[1135.5529 1122.5474 1110.4327 1087.9885 1145.4143 1140.6273 1135.6115\n",
      " 1149.174  1174.2701 1215.2115 1233.9827 1245.7291 1248.0344]\n",
      "[1109.1  1088.35 1084.65 1085.55 1167.35 1167.5  1166.6  1176.3  1183.\n",
      " 1219.6  1222.35 1248.35 1254.45]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target_model</th>\n",
       "      <th>conv1d</th>\n",
       "      <th>LSTM</th>\n",
       "      <th>GRU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.981972</td>\n",
       "      <td>48.742985</td>\n",
       "      <td>278.898682</td>\n",
       "      <td>229.581787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target_model     conv1d        LSTM         GRU\n",
       "0     26.981972  48.742985  278.898682  229.581787"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = model_scores_comparator(\"tata_steel/TATASTEEL.NS (1).csv\", \"tata_steel/tata_steel_final_posts.xlsx\", \n",
    "                             \"final_bert\", \"tata steel\", [\"conv1d\",\"LSTM\",\"GRU\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad64e657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 1364 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001932C02D5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "Epoch 00155: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00255: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 10.6061 - mae: 10.6061 - mse: 183.6140\n",
      "1/1 [==============================] - 0s 480ms/step - loss: 16.6612 - mae: 16.6612 - mse: 479.5851\n",
      "scaled_model\n",
      "[802.32715 800.06696 794.68695 791.75793 791.4672  793.3288  794.8532\n",
      " 794.66565 787.3845  789.2938  792.50085]\n",
      "[801.65 794.65 781.15 788.8  810.3  813.75 808.95 805.05 792.5  802.8\n",
      " 790.8 ]\n",
      "scaled_model\n",
      "[794.7976  796.802   789.7172  794.16956 808.69275 816.62695 805.85\n",
      " 797.77545 763.6633  782.0082  791.0225 ]\n",
      "[801.65 794.65 781.15 788.8  810.3  813.75 808.95 805.05 792.5  802.8\n",
      " 790.8 ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target_model</th>\n",
       "      <th>conv1d</th>\n",
       "      <th>LSTM</th>\n",
       "      <th>GRU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.606112</td>\n",
       "      <td>16.661226</td>\n",
       "      <td>106.646545</td>\n",
       "      <td>87.65094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target_model     conv1d        LSTM       GRU\n",
       "0     10.606112  16.661226  106.646545  87.65094"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = model_scores_comparator(\"icici/ICICIBANK.NS.csv\", \"icici/icici_bank_final_posts.xlsx\", \n",
    "                             \"final_bert\", \"icici\", [\"conv1d\",\"LSTM\",\"GRU\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a0371d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 517 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001914D35E310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00256: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.9299 - mae: 2.9299 - mse: 12.1340\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 4.3033 - mae: 4.3033 - mse: 40.9895\n",
      "scaled_model\n",
      "[214.65805 216.33624 219.05553 225.66968 230.60774 233.77744 232.622\n",
      " 231.33575 230.19392 229.92274 230.17053]\n",
      "[214.6  217.6  220.2  227.75 232.15 234.45 230.2  231.25 230.15 232.25\n",
      " 232.45]\n",
      "scaled_model\n",
      "[215.96233 217.58995 218.2951  226.66629 229.85011 232.40779 229.33708\n",
      " 231.0536  230.60959 231.98804 231.61888]\n",
      "[214.6  217.6  220.2  227.75 232.15 234.45 230.2  231.25 230.15 232.25\n",
      " 232.45]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target_model</th>\n",
       "      <th>conv1d</th>\n",
       "      <th>LSTM</th>\n",
       "      <th>GRU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.929909</td>\n",
       "      <td>4.303325</td>\n",
       "      <td>13.919815</td>\n",
       "      <td>11.315048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target_model    conv1d       LSTM        GRU\n",
       "0      2.929909  4.303325  13.919815  11.315048"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = model_scores_comparator(\"itc/ITC.NS.csv\", \"itc/itc_final_posts.xlsx\", \n",
    "                             \"final_bert\", \"itc\", [\"conv1d\",\"LSTM\",\"GRU\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f70696a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00155: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00255: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 96.0099 - mae: 96.0099 - mse: 25539.9785\n",
      "1/1 [==============================] - 1s 695ms/step - loss: 113.8571 - mae: 113.8571 - mse: 27533.9277\n",
      "scaled_model\n",
      "[8506.652 8530.543 8552.735 8562.858 8570.454 8602.898 8630.671 8642.096\n",
      " 8650.431 8694.767 8715.952 8726.964]\n",
      "[8820.2  8550.95 8597.3  8559.4  8515.25 8593.65 8550.55 8511.65 8599.45\n",
      " 8949.45 8805.45 8737.15]\n",
      "scaled_model\n",
      "[8766.409 8624.287 8584.201 8574.237 8517.011 8597.31  8564.397 8577.385\n",
      " 8662.956 8836.088 8747.038 8682.091]\n",
      "[8820.2  8550.95 8597.3  8559.4  8515.25 8593.65 8550.55 8511.65 8599.45\n",
      " 8949.45 8805.45 8737.15]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target_model</th>\n",
       "      <th>conv1d</th>\n",
       "      <th>LSTM</th>\n",
       "      <th>GRU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96.009926</td>\n",
       "      <td>113.857094</td>\n",
       "      <td>1062.344727</td>\n",
       "      <td>530.405273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target_model      conv1d         LSTM         GRU\n",
       "0     96.009926  113.857094  1062.344727  530.405273"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = model_scores_comparator(\"maruti_suzuki/MARUTI.NS.csv\", \"maruti_suzuki/maruti_suzuki_final_posts.xlsx\", \n",
    "                             \"final_bert\", \"maruti suzuki\", [\"conv1d\",\"LSTM\",\"GRU\"])\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ws_env",
   "language": "python",
   "name": "ws_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
