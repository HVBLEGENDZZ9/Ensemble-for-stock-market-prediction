{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55443fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "df_stock = pd.read_csv(\"icici/ICICIBANK.NS.csv\",\n",
    "                 parse_dates = [\"Date\"],\n",
    "                 index_col = [\"Date\"])\n",
    "df_posts = pd.read_excel(\"icici/icici_bank_final_posts.xlsx\")\n",
    "# removing the unnecessary columns\n",
    "df_posts.drop([\"Unnamed: 0\"], axis=1,inplace=True)\n",
    "# removing spam posts\n",
    "df_posts = df_posts[df_posts.Spam==0.0]\n",
    "df_posts.drop([\"Spam\"],axis=1,inplace=True)\n",
    "# sliding a window of 7 days and adding all the TIs\n",
    "from stock_helper import prepare_data\n",
    "x,y = prepare_data(df_stock)\n",
    "# slicing the data\n",
    "final_x = x[np.datetime64(\"2021-11-13\"):]\n",
    "final_y = y[np.datetime64(\"2021-11-13\"):]\n",
    "# reversing the posts data\n",
    "df_posts = df_posts[::-1]\n",
    "final_posts = df_posts[7:]\n",
    "# loading the sentiment analysis model\n",
    "sent_model = tf.keras.models.load_model(\"final_bert\")\n",
    "# removing duplicates from the data\n",
    "final_posts.drop_duplicates(subset=['Messages'])\n",
    "# calculating the sentiments score\n",
    "sentiments = []\n",
    "prev = np.datetime64(\"2015-11-12 21:31:26\")\n",
    "for i in final_y.index:\n",
    "    total=0\n",
    "    cnt=0\n",
    "    for j in final_posts.itertuples():\n",
    "        _,msg,time = j\n",
    "        if np.datetime64(time)<np.datetime64(i) and np.datetime64(time)>prev:\n",
    "            total += tf.squeeze(sent_model.predict([msg])).numpy()\n",
    "            cnt+=1\n",
    "    prev = np.datetime64(i)\n",
    "    if(cnt==0):\n",
    "        sentiments.append(0)\n",
    "    else:\n",
    "        sentiments.append(total/cnt)\n",
    "# getting indices where sentiments score is 0\n",
    "zero_index = []\n",
    "for i,j in enumerate(sentiments):\n",
    "    if(j==0):\n",
    "        zero_index.append(i)\n",
    "# removing all the zero values indices\n",
    "sentiments = np.delete(sentiments,zero_index)\n",
    "final_x_zeros = final_x.copy()\n",
    "final_y_zeros = final_y.copy()\n",
    "final_y_zeros = final_y_zeros.to_frame()\n",
    "final_x_zeros['removal_assist'] = np.arange(0,len(final_x),1)\n",
    "final_y_zeros['removal_assist'] = np.arange(0,len(final_x),1)\n",
    "final_y_zeros = final_y_zeros[final_y_zeros.removal_assist.isin(zero_index)==False]\n",
    "final_x_zeros = final_x_zeros[final_x_zeros.removal_assist.isin(zero_index)==False]\n",
    "# removing the added helper column\n",
    "final_x_zeros.drop([\"removal_assist\"], axis=1,inplace=True)\n",
    "final_y_zeros.drop([\"removal_assist\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3564884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46964598, 0.7110796 , 0.830842  , ..., 0.47434157, 0.5546069 ,\n",
       "        0.7407407 ],\n",
       "       [0.49432564, 0.72036934, 0.819458  , ..., 0.37842518, 0.53776145,\n",
       "        0.7037037 ],\n",
       "       [0.5260892 , 0.73180676, 0.8039284 , ..., 0.33568484, 0.5818709 ,\n",
       "        0.5925926 ],\n",
       "       ...,\n",
       "       [0.9687238 , 0.98316383, 0.7430401 , ..., 0.23337865, 0.32989419,\n",
       "        0.25925925],\n",
       "       [0.965055  , 0.9778986 , 0.73816586, ..., 0.21261415, 0.42023087,\n",
       "        0.25925925],\n",
       "       [0.96308565, 0.94291973, 0.68118954, ..., 0.34671447, 0.65432334,\n",
       "        0.25925925]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "final_x_zeros_scaled = mms.fit_transform(final_x_zeros)\n",
    "final_x_zeros_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cbcee0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-11-16</th>\n",
       "      <td>0.926458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-17</th>\n",
       "      <td>0.923124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-18</th>\n",
       "      <td>0.925064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-22</th>\n",
       "      <td>0.911847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-23</th>\n",
       "      <td>0.911665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-24</th>\n",
       "      <td>0.921790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-25</th>\n",
       "      <td>0.910695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-26</th>\n",
       "      <td>0.875712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-29</th>\n",
       "      <td>0.871105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-30</th>\n",
       "      <td>0.866194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-01</th>\n",
       "      <td>0.882381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-02</th>\n",
       "      <td>0.875955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-03</th>\n",
       "      <td>0.868558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-06</th>\n",
       "      <td>0.860373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-07</th>\n",
       "      <td>0.890809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-08</th>\n",
       "      <td>0.913544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-09</th>\n",
       "      <td>0.915484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-10</th>\n",
       "      <td>0.919122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-13</th>\n",
       "      <td>0.914272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-14</th>\n",
       "      <td>0.919910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-15</th>\n",
       "      <td>0.912150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-16</th>\n",
       "      <td>0.898690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-20</th>\n",
       "      <td>0.860859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-21</th>\n",
       "      <td>0.873469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-22</th>\n",
       "      <td>0.888566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-23</th>\n",
       "      <td>0.886747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-24</th>\n",
       "      <td>0.881654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-27</th>\n",
       "      <td>0.892446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-28</th>\n",
       "      <td>0.892203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-29</th>\n",
       "      <td>0.892082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-30</th>\n",
       "      <td>0.892082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-03</th>\n",
       "      <td>0.927246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-04</th>\n",
       "      <td>0.937129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05</th>\n",
       "      <td>0.955560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-06</th>\n",
       "      <td>0.951922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-07</th>\n",
       "      <td>0.961865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-10</th>\n",
       "      <td>0.983085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-11</th>\n",
       "      <td>0.982964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-12</th>\n",
       "      <td>0.998848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-13</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-20</th>\n",
       "      <td>0.982478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-21</th>\n",
       "      <td>0.975506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-24</th>\n",
       "      <td>0.968170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-25</th>\n",
       "      <td>0.972050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-27</th>\n",
       "      <td>0.963563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-28</th>\n",
       "      <td>0.947193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-31</th>\n",
       "      <td>0.956469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-01</th>\n",
       "      <td>0.982539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-02</th>\n",
       "      <td>0.986722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-03</th>\n",
       "      <td>0.980902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-04</th>\n",
       "      <td>0.976173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-08</th>\n",
       "      <td>0.960956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-09</th>\n",
       "      <td>0.973445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-11</th>\n",
       "      <td>0.958894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Close\n",
       "Date                \n",
       "2021-11-16  0.926458\n",
       "2021-11-17  0.923124\n",
       "2021-11-18  0.925064\n",
       "2021-11-22  0.911847\n",
       "2021-11-23  0.911665\n",
       "2021-11-24  0.921790\n",
       "2021-11-25  0.910695\n",
       "2021-11-26  0.875712\n",
       "2021-11-29  0.871105\n",
       "2021-11-30  0.866194\n",
       "2021-12-01  0.882381\n",
       "2021-12-02  0.875955\n",
       "2021-12-03  0.868558\n",
       "2021-12-06  0.860373\n",
       "2021-12-07  0.890809\n",
       "2021-12-08  0.913544\n",
       "2021-12-09  0.915484\n",
       "2021-12-10  0.919122\n",
       "2021-12-13  0.914272\n",
       "2021-12-14  0.919910\n",
       "2021-12-15  0.912150\n",
       "2021-12-16  0.898690\n",
       "2021-12-20  0.860859\n",
       "2021-12-21  0.873469\n",
       "2021-12-22  0.888566\n",
       "2021-12-23  0.886747\n",
       "2021-12-24  0.881654\n",
       "2021-12-27  0.892446\n",
       "2021-12-28  0.892203\n",
       "2021-12-29  0.892082\n",
       "2021-12-30  0.892082\n",
       "2022-01-03  0.927246\n",
       "2022-01-04  0.937129\n",
       "2022-01-05  0.955560\n",
       "2022-01-06  0.951922\n",
       "2022-01-07  0.961865\n",
       "2022-01-10  0.983085\n",
       "2022-01-11  0.982964\n",
       "2022-01-12  0.998848\n",
       "2022-01-13  1.000000\n",
       "2022-01-20  0.982478\n",
       "2022-01-21  0.975506\n",
       "2022-01-24  0.968170\n",
       "2022-01-25  0.972050\n",
       "2022-01-27  0.963563\n",
       "2022-01-28  0.947193\n",
       "2022-01-31  0.956469\n",
       "2022-02-01  0.982539\n",
       "2022-02-02  0.986722\n",
       "2022-02-03  0.980902\n",
       "2022-02-04  0.976173\n",
       "2022-02-08  0.960956\n",
       "2022-02-09  0.973445\n",
       "2022-02-11  0.958894"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = final_y_zeros.max()\n",
    "final_y_zeros= final_y_zeros/k\n",
    "final_y_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "070c3fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 737ms/step - loss: 10.6543 - mae: 10.6543 - mse: 175.6807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[10.654330253601074, 10.654330253601074, 175.6807098388672]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nbeats = tf.keras.models.load_model(\"nbeats_icici\")\n",
    "model_nbeats.evaluate(final_x_zeros[43:],final_y_zeros[43:]*k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49466596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 71)]              0         \n",
      "                                                                 \n",
      " lambda_1 (Lambda)           (None, 1, 71)             0         \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (None, 1, 128)            77184     \n",
      "                                                                 \n",
      " gru_4 (GRU)                 (None, 1, 128)            99072     \n",
      "                                                                 \n",
      " gru_5 (GRU)                 (None, 128)               99072     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 275,457\n",
      "Trainable params: 275,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "inputs = tf.keras.layers.Input(shape=(71))\n",
    "x = tf.keras.layers.Lambda(lambda x : tf.expand_dims(x,axis=1))(inputs)\n",
    "x = tf.keras.layers.GRU(128, return_sequences=True)(x)\n",
    "x = tf.keras.layers.GRU(128, return_sequences=True)(x)\n",
    "x = tf.keras.layers.GRU(128)(x)\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "model = tf.keras.models.Model(inputs = inputs, outputs = outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4efe238a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2/2 [==============================] - 7s 685ms/step - loss: 0.8963 - mae: 0.8963 - mse: 0.8061 - val_loss: 0.7132 - val_mae: 0.7132 - val_mse: 0.5108 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6977 - mae: 0.6977 - mse: 0.4920 - val_loss: 0.3602 - val_mae: 0.3602 - val_mse: 0.1373 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4420 - mae: 0.4420 - mse: 0.2142 - val_loss: 0.1487 - val_mae: 0.1487 - val_mse: 0.0365 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.2102 - mae: 0.2102 - mse: 0.0628 - val_loss: 0.7173 - val_mae: 0.7173 - val_mse: 0.5448 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.3135 - mae: 0.3135 - mse: 0.1895 - val_loss: 0.7078 - val_mae: 0.7078 - val_mse: 0.5259 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.2864 - mae: 0.2864 - mse: 0.1559 - val_loss: 0.3896 - val_mae: 0.3896 - val_mse: 0.1668 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.1751 - mae: 0.1751 - mse: 0.0515 - val_loss: 0.1277 - val_mae: 0.1277 - val_mse: 0.0249 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.1593 - mae: 0.1593 - mse: 0.0322 - val_loss: 0.0703 - val_mae: 0.0703 - val_mse: 0.0079 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1654 - mae: 0.1654 - mse: 0.0355 - val_loss: 0.0826 - val_mae: 0.0826 - val_mse: 0.0117 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1361 - mae: 0.1361 - mse: 0.0243 - val_loss: 0.1829 - val_mae: 0.1829 - val_mse: 0.0378 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1077 - mae: 0.1077 - mse: 0.0175 - val_loss: 0.2714 - val_mae: 0.2714 - val_mse: 0.0772 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1168 - mae: 0.1168 - mse: 0.0230 - val_loss: 0.2552 - val_mae: 0.2552 - val_mse: 0.0675 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1076 - mae: 0.1076 - mse: 0.0186 - val_loss: 0.1534 - val_mae: 0.1534 - val_mse: 0.0247 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0780 - mae: 0.0780 - mse: 0.0087 - val_loss: 0.0471 - val_mae: 0.0471 - val_mse: 0.0027 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0700 - mae: 0.0700 - mse: 0.0074 - val_loss: 0.0437 - val_mae: 0.0437 - val_mse: 0.0022 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0490 - mae: 0.0490 - mse: 0.0041 - val_loss: 0.0938 - val_mae: 0.0938 - val_mse: 0.0090 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0498 - mae: 0.0498 - mse: 0.0032 - val_loss: 0.0641 - val_mae: 0.0641 - val_mse: 0.0042 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0372 - mae: 0.0372 - mse: 0.0017 - val_loss: 0.0263 - val_mae: 0.0263 - val_mse: 7.6608e-04 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0362 - mae: 0.0362 - mse: 0.0018 - val_loss: 0.0231 - val_mae: 0.0231 - val_mse: 7.6461e-04 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0258 - mae: 0.0258 - mse: 9.8051e-04 - val_loss: 0.0193 - val_mae: 0.0193 - val_mse: 6.7495e-04 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0259 - mae: 0.0259 - mse: 9.4150e-04 - val_loss: 0.0501 - val_mae: 0.0501 - val_mse: 0.0029 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0289 - mae: 0.0289 - mse: 0.0017 - val_loss: 0.0489 - val_mae: 0.0489 - val_mse: 0.0028 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0259 - mae: 0.0259 - mse: 0.0013 - val_loss: 0.0260 - val_mae: 0.0260 - val_mse: 8.3422e-04 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0288 - mae: 0.0288 - mse: 0.0011 - val_loss: 0.0338 - val_mae: 0.0338 - val_mse: 0.0013 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0236 - mae: 0.0236 - mse: 9.8806e-04 - val_loss: 0.0395 - val_mae: 0.0395 - val_mse: 0.0017 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0202 - mae: 0.0202 - mse: 7.4060e-04 - val_loss: 0.0124 - val_mae: 0.0124 - val_mse: 2.1464e-04 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0196 - mae: 0.0196 - mse: 5.0441e-04 - val_loss: 0.0120 - val_mae: 0.0120 - val_mse: 2.7344e-04 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0113 - mae: 0.0113 - mse: 3.1539e-04 - val_loss: 0.0278 - val_mae: 0.0278 - val_mse: 9.4088e-04 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0217 - mae: 0.0217 - mse: 5.6291e-04 - val_loss: 0.0205 - val_mae: 0.0205 - val_mse: 6.6498e-04 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0156 - mae: 0.0156 - mse: 4.9532e-04 - val_loss: 0.0294 - val_mae: 0.0294 - val_mse: 0.0011 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0190 - mae: 0.0190 - mse: 5.0962e-04 - val_loss: 0.0245 - val_mae: 0.0245 - val_mse: 8.2957e-04 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0156 - mae: 0.0156 - mse: 4.1848e-04 - val_loss: 0.0233 - val_mae: 0.0233 - val_mse: 8.8319e-04 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0135 - mae: 0.0135 - mse: 3.5452e-04 - val_loss: 0.0199 - val_mae: 0.0199 - val_mse: 6.2343e-04 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.1642e-04 - val_loss: 0.0178 - val_mae: 0.0178 - val_mse: 6.2243e-04 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1664e-04 - val_loss: 0.0241 - val_mae: 0.0241 - val_mse: 9.7137e-04 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0123 - mae: 0.0123 - mse: 2.7952e-04 - val_loss: 0.0218 - val_mae: 0.0218 - val_mse: 8.2237e-04 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5695e-04 - val_loss: 0.0153 - val_mae: 0.0153 - val_mse: 4.8991e-04 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.1021e-04 - val_loss: 0.0257 - val_mae: 0.0257 - val_mse: 0.0011 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0130 - mae: 0.0130 - mse: 2.5758e-04 - val_loss: 0.0203 - val_mae: 0.0203 - val_mse: 7.9234e-04 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.0035e-04 - val_loss: 0.0220 - val_mae: 0.0220 - val_mse: 9.0343e-04 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.1224e-04 - val_loss: 0.0174 - val_mae: 0.0174 - val_mse: 5.9371e-04 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0086 - mae: 0.0086 - mse: 1.6375e-04 - val_loss: 0.0177 - val_mae: 0.0177 - val_mse: 4.3822e-04 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.0835e-04 - val_loss: 0.0183 - val_mae: 0.0183 - val_mse: 4.6141e-04 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0113 - mae: 0.0113 - mse: 1.9424e-04 - val_loss: 0.0195 - val_mae: 0.0195 - val_mse: 5.1387e-04 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0130 - mae: 0.0130 - mse: 2.1967e-04 - val_loss: 0.0240 - val_mae: 0.0240 - val_mse: 9.5904e-04 - lr: 0.0010\n",
      "Epoch 46/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0129 - mae: 0.0129 - mse: 2.6077e-04 - val_loss: 0.0153 - val_mae: 0.0153 - val_mse: 3.7214e-04 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0104 - mae: 0.0104 - mse: 1.8462e-04 - val_loss: 0.0160 - val_mae: 0.0160 - val_mse: 4.7402e-04 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0099 - mae: 0.0099 - mse: 1.8377e-04 - val_loss: 0.0097 - val_mae: 0.0097 - val_mse: 1.9931e-04 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.1731e-04 - val_loss: 0.0138 - val_mae: 0.0138 - val_mse: 3.3292e-04 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0118 - mae: 0.0118 - mse: 2.9242e-04 - val_loss: 0.0155 - val_mae: 0.0155 - val_mse: 2.8030e-04 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0133 - mae: 0.0133 - mse: 2.2940e-04 - val_loss: 0.0437 - val_mae: 0.0437 - val_mse: 0.0021 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0302 - mae: 0.0302 - mse: 0.0010 - val_loss: 0.0169 - val_mae: 0.0169 - val_mse: 4.7309e-04 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0148 - mae: 0.0148 - mse: 3.0389e-04 - val_loss: 0.0273 - val_mae: 0.0273 - val_mse: 9.4907e-04 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0214 - mae: 0.0214 - mse: 6.8482e-04 - val_loss: 0.0513 - val_mae: 0.0513 - val_mse: 0.0031 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0387 - mae: 0.0387 - mse: 0.0017 - val_loss: 0.0267 - val_mae: 0.0267 - val_mse: 0.0012 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0228 - mae: 0.0228 - mse: 7.5738e-04 - val_loss: 0.0478 - val_mae: 0.0478 - val_mse: 0.0029 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0393 - mae: 0.0393 - mse: 0.0020 - val_loss: 0.0204 - val_mae: 0.0204 - val_mse: 6.4360e-04 - lr: 0.0010\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0176 - mae: 0.0176 - mse: 4.7800e-04 - val_loss: 0.0253 - val_mae: 0.0253 - val_mse: 0.0011 - lr: 0.0010\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0205 - mae: 0.0205 - mse: 5.8419e-04 - val_loss: 0.0323 - val_mae: 0.0323 - val_mse: 0.0013 - lr: 0.0010\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0207 - mae: 0.0207 - mse: 5.6425e-04 - val_loss: 0.0200 - val_mae: 0.0200 - val_mse: 7.0288e-04 - lr: 0.0010\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0197 - mae: 0.0197 - mse: 5.0247e-04 - val_loss: 0.0204 - val_mae: 0.0204 - val_mse: 5.4585e-04 - lr: 0.0010\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0125 - mae: 0.0125 - mse: 2.2122e-04 - val_loss: 0.0158 - val_mae: 0.0158 - val_mse: 3.3749e-04 - lr: 0.0010\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0096 - mae: 0.0096 - mse: 1.7713e-04 - val_loss: 0.0144 - val_mae: 0.0144 - val_mse: 2.9686e-04 - lr: 0.0010\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0090 - mae: 0.0090 - mse: 1.3161e-04 - val_loss: 0.0138 - val_mae: 0.0138 - val_mse: 3.1902e-04 - lr: 0.0010\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0085 - mae: 0.0085 - mse: 1.2923e-04 - val_loss: 0.0156 - val_mae: 0.0156 - val_mse: 4.3591e-04 - lr: 0.0010\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0101 - mae: 0.0101 - mse: 1.8330e-04 - val_loss: 0.0144 - val_mae: 0.0144 - val_mse: 3.0708e-04 - lr: 0.0010\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0115 - mae: 0.0115 - mse: 1.8976e-04 - val_loss: 0.0294 - val_mae: 0.0294 - val_mse: 0.0012 - lr: 0.0010\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.1910e-04 - val_loss: 0.0154 - val_mae: 0.0154 - val_mse: 3.2791e-04 - lr: 0.0010\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0170 - mae: 0.0170 - mse: 3.7138e-04 - val_loss: 0.0146 - val_mae: 0.0146 - val_mse: 3.7836e-04 - lr: 0.0010\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0075 - mae: 0.0075 - mse: 1.0250e-04 - val_loss: 0.0137 - val_mae: 0.0137 - val_mse: 3.3438e-04 - lr: 0.0010\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0063 - mae: 0.0063 - mse: 9.3278e-05 - val_loss: 0.0144 - val_mae: 0.0144 - val_mse: 2.9189e-04 - lr: 0.0010\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0098 - mae: 0.0098 - mse: 1.5094e-04 - val_loss: 0.0144 - val_mae: 0.0144 - val_mse: 2.9453e-04 - lr: 0.0010\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0068 - mae: 0.0068 - mse: 1.0686e-04 - val_loss: 0.0227 - val_mae: 0.0227 - val_mse: 8.0784e-04 - lr: 0.0010\n",
      "Epoch 74/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0154 - mae: 0.0154 - mse: 3.4134e-04 - val_loss: 0.0284 - val_mae: 0.0284 - val_mse: 0.0011 - lr: 0.0010\n",
      "Epoch 75/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0279 - mae: 0.0279 - mse: 8.5431e-04 - val_loss: 0.0194 - val_mae: 0.0194 - val_mse: 5.2335e-04 - lr: 0.0010\n",
      "Epoch 76/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0191 - mae: 0.0191 - mse: 4.3293e-04 - val_loss: 0.0444 - val_mae: 0.0444 - val_mse: 0.0023 - lr: 0.0010\n",
      "Epoch 77/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0286 - mae: 0.0286 - mse: 9.9647e-04 - val_loss: 0.0204 - val_mae: 0.0204 - val_mse: 5.7923e-04 - lr: 0.0010\n",
      "Epoch 78/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0197 - mae: 0.0197 - mse: 4.9776e-04 - val_loss: 0.0192 - val_mae: 0.0192 - val_mse: 4.9018e-04 - lr: 0.0010\n",
      "Epoch 79/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0147 - mae: 0.0147 - mse: 3.0444e-04 - val_loss: 0.0264 - val_mae: 0.0264 - val_mse: 0.0011 - lr: 0.0010\n",
      "Epoch 80/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0149 - mae: 0.0149 - mse: 3.1086e-04 - val_loss: 0.0212 - val_mae: 0.0212 - val_mse: 6.2241e-04 - lr: 0.0010\n",
      "Epoch 81/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0172 - mae: 0.0172 - mse: 3.8396e-04 - val_loss: 0.0341 - val_mae: 0.0341 - val_mse: 0.0015 - lr: 0.0010\n",
      "Epoch 82/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0229 - mae: 0.0229 - mse: 5.9223e-04 - val_loss: 0.0172 - val_mae: 0.0172 - val_mse: 4.5376e-04 - lr: 0.0010\n",
      "Epoch 83/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.7132e-04 - val_loss: 0.0253 - val_mae: 0.0253 - val_mse: 8.4508e-04 - lr: 0.0010\n",
      "Epoch 84/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0201 - mae: 0.0201 - mse: 4.9496e-04 - val_loss: 0.0274 - val_mae: 0.0274 - val_mse: 0.0011 - lr: 0.0010\n",
      "Epoch 85/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0184 - mae: 0.0184 - mse: 4.3290e-04 - val_loss: 0.0181 - val_mae: 0.0181 - val_mse: 4.4081e-04 - lr: 0.0010\n",
      "Epoch 86/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0155 - mae: 0.0155 - mse: 2.6600e-04 - val_loss: 0.0177 - val_mae: 0.0177 - val_mse: 4.6952e-04 - lr: 0.0010\n",
      "Epoch 87/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0079 - mae: 0.0079 - mse: 1.2868e-04 - val_loss: 0.0191 - val_mae: 0.0191 - val_mse: 5.8282e-04 - lr: 0.0010\n",
      "Epoch 88/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.3859e-04 - val_loss: 0.0274 - val_mae: 0.0274 - val_mse: 0.0010 - lr: 0.0010\n",
      "Epoch 89/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0233 - mae: 0.0233 - mse: 6.4982e-04 - val_loss: 0.0373 - val_mae: 0.0373 - val_mse: 0.0018 - lr: 0.0010\n",
      "Epoch 90/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0310 - mae: 0.0310 - mse: 0.0011 - val_loss: 0.0373 - val_mae: 0.0373 - val_mse: 0.0018 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0233 - mae: 0.0233 - mse: 6.5873e-04 - val_loss: 0.0246 - val_mae: 0.0246 - val_mse: 8.3901e-04 - lr: 0.0010\n",
      "Epoch 92/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0209 - mae: 0.0209 - mse: 4.8921e-04 - val_loss: 0.0189 - val_mae: 0.0189 - val_mse: 5.1188e-04 - lr: 0.0010\n",
      "Epoch 93/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0097 - mae: 0.0097 - mse: 1.6488e-04 - val_loss: 0.0172 - val_mae: 0.0172 - val_mse: 4.0870e-04 - lr: 0.0010\n",
      "Epoch 94/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0104 - mae: 0.0104 - mse: 1.4276e-04 - val_loss: 0.0180 - val_mae: 0.0180 - val_mse: 4.4756e-04 - lr: 0.0010\n",
      "Epoch 95/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0078 - mae: 0.0078 - mse: 1.2371e-04 - val_loss: 0.0165 - val_mae: 0.0165 - val_mse: 3.7782e-04 - lr: 0.0010\n",
      "Epoch 96/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0098 - mae: 0.0098 - mse: 1.2428e-04 - val_loss: 0.0201 - val_mae: 0.0201 - val_mse: 6.4631e-04 - lr: 0.0010\n",
      "Epoch 97/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0111 - mae: 0.0111 - mse: 1.8929e-04 - val_loss: 0.0157 - val_mae: 0.0157 - val_mse: 3.4472e-04 - lr: 0.0010\n",
      "Epoch 98/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0124 - mae: 0.0124 - mse: 1.7771e-04 - val_loss: 0.0205 - val_mae: 0.0205 - val_mse: 6.5923e-04 - lr: 0.0010\n",
      "Epoch 99/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0097 - mae: 0.0097 - mse: 1.5210e-04 - val_loss: 0.0148 - val_mae: 0.0148 - val_mse: 3.1878e-04 - lr: 0.0010\n",
      "Epoch 100/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0059 - mae: 0.0059 - mse: 6.1349e-05 - val_loss: 0.0138 - val_mae: 0.0138 - val_mse: 2.7918e-04 - lr: 0.0010\n",
      "Epoch 101/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0091 - mae: 0.0091 - mse: 1.1897e-04 - val_loss: 0.0147 - val_mae: 0.0147 - val_mse: 3.1355e-04 - lr: 0.0010\n",
      "Epoch 102/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0065 - mae: 0.0065 - mse: 7.4837e-05 - val_loss: 0.0214 - val_mae: 0.0214 - val_mse: 7.2019e-04 - lr: 0.0010\n",
      "Epoch 103/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0113 - mae: 0.0113 - mse: 1.7959e-04 - val_loss: 0.0175 - val_mae: 0.0175 - val_mse: 4.3938e-04 - lr: 0.0010\n",
      "Epoch 104/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0175 - mae: 0.0175 - mse: 3.3333e-04 - val_loss: 0.0160 - val_mae: 0.0160 - val_mse: 3.6466e-04 - lr: 0.0010\n",
      "Epoch 105/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0094 - mae: 0.0094 - mse: 1.7566e-04 - val_loss: 0.0314 - val_mae: 0.0314 - val_mse: 0.0013 - lr: 0.0010\n",
      "Epoch 106/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0180 - mae: 0.0180 - mse: 4.3414e-04 - val_loss: 0.0150 - val_mae: 0.0150 - val_mse: 3.2142e-04 - lr: 0.0010\n",
      "Epoch 107/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0111 - mae: 0.0111 - mse: 1.5373e-04 - val_loss: 0.0296 - val_mae: 0.0296 - val_mse: 0.0011 - lr: 0.0010\n",
      "Epoch 108/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0228 - mae: 0.0228 - mse: 5.7654e-04 - val_loss: 0.0146 - val_mae: 0.0146 - val_mse: 3.3805e-04 - lr: 0.0010\n",
      "Epoch 109/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0089 - mae: 0.0089 - mse: 1.3417e-04 - val_loss: 0.0285 - val_mae: 0.0285 - val_mse: 0.0010 - lr: 0.0010\n",
      "Epoch 110/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0270 - mae: 0.0270 - mse: 7.8033e-04 - val_loss: 0.0177 - val_mae: 0.0177 - val_mse: 4.9441e-04 - lr: 0.0010\n",
      "Epoch 111/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0124 - mae: 0.0124 - mse: 2.2823e-04 - val_loss: 0.0129 - val_mae: 0.0129 - val_mse: 2.5252e-04 - lr: 0.0010\n",
      "Epoch 112/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0064 - mae: 0.0064 - mse: 8.3344e-05 - val_loss: 0.0152 - val_mae: 0.0152 - val_mse: 3.6038e-04 - lr: 0.0010\n",
      "Epoch 113/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0051 - mae: 0.0051 - mse: 6.9507e-05 - val_loss: 0.0137 - val_mae: 0.0137 - val_mse: 2.7272e-04 - lr: 0.0010\n",
      "Epoch 114/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0062 - mae: 0.0062 - mse: 6.8641e-05 - val_loss: 0.0173 - val_mae: 0.0173 - val_mse: 4.4200e-04 - lr: 0.0010\n",
      "Epoch 115/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0061 - mae: 0.0061 - mse: 7.0376e-05 - val_loss: 0.0167 - val_mae: 0.0167 - val_mse: 3.8445e-04 - lr: 0.0010\n",
      "Epoch 116/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0045 - mae: 0.0045 - mse: 4.8821e-05 - val_loss: 0.0162 - val_mae: 0.0162 - val_mse: 3.6453e-04 - lr: 0.0010\n",
      "Epoch 117/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0063 - mae: 0.0063 - mse: 7.5042e-05 - val_loss: 0.0156 - val_mae: 0.0156 - val_mse: 3.4527e-04 - lr: 0.0010\n",
      "Epoch 118/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0113 - mae: 0.0113 - mse: 1.8120e-04 - val_loss: 0.0176 - val_mae: 0.0176 - val_mse: 4.7895e-04 - lr: 0.0010\n",
      "Epoch 119/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0121 - mae: 0.0121 - mse: 1.9131e-04 - val_loss: 0.0185 - val_mae: 0.0185 - val_mse: 4.9351e-04 - lr: 0.0010\n",
      "Epoch 120/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0132 - mae: 0.0132 - mse: 2.2923e-04 - val_loss: 0.0195 - val_mae: 0.0195 - val_mse: 5.9683e-04 - lr: 0.0010\n",
      "Epoch 121/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0092 - mae: 0.0092 - mse: 1.2533e-04 - val_loss: 0.0178 - val_mae: 0.0178 - val_mse: 4.3125e-04 - lr: 0.0010\n",
      "Epoch 122/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0044 - mae: 0.0044 - mse: 4.8825e-05 - val_loss: 0.0160 - val_mae: 0.0160 - val_mse: 3.4221e-04 - lr: 0.0010\n",
      "Epoch 123/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0050 - mae: 0.0050 - mse: 5.3080e-05 - val_loss: 0.0146 - val_mae: 0.0146 - val_mse: 2.9220e-04 - lr: 0.0010\n",
      "Epoch 124/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0051 - mae: 0.0051 - mse: 5.0611e-05 - val_loss: 0.0274 - val_mae: 0.0274 - val_mse: 9.6700e-04 - lr: 0.0010\n",
      "Epoch 125/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0156 - mae: 0.0156 - mse: 2.9726e-04 - val_loss: 0.0129 - val_mae: 0.0129 - val_mse: 2.3851e-04 - lr: 0.0010\n",
      "Epoch 126/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0138 - mae: 0.0138 - mse: 2.0721e-04 - val_loss: 0.0153 - val_mae: 0.0153 - val_mse: 3.6582e-04 - lr: 0.0010\n",
      "Epoch 127/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0080 - mae: 0.0080 - mse: 1.4442e-04 - val_loss: 0.0231 - val_mae: 0.0231 - val_mse: 7.5027e-04 - lr: 0.0010\n",
      "Epoch 128/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0128 - mae: 0.0128 - mse: 2.0724e-04 - val_loss: 0.0149 - val_mae: 0.0149 - val_mse: 3.2894e-04 - lr: 0.0010\n",
      "Epoch 129/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0155 - mae: 0.0155 - mse: 2.9179e-04 - val_loss: 0.0237 - val_mae: 0.0237 - val_mse: 8.4223e-04 - lr: 0.0010\n",
      "Epoch 130/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0093 - mae: 0.0093 - mse: 1.4113e-04 - val_loss: 0.0152 - val_mae: 0.0152 - val_mse: 3.1445e-04 - lr: 0.0010\n",
      "Epoch 131/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0092 - mae: 0.0092 - mse: 1.2544e-04 - val_loss: 0.0211 - val_mae: 0.0211 - val_mse: 7.1282e-04 - lr: 0.0010\n",
      "Epoch 132/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0096 - mae: 0.0096 - mse: 1.4295e-04 - val_loss: 0.0174 - val_mae: 0.0174 - val_mse: 4.4791e-04 - lr: 0.0010\n",
      "Epoch 133/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0157 - mae: 0.0157 - mse: 2.6875e-04 - val_loss: 0.0165 - val_mae: 0.0165 - val_mse: 3.6852e-04 - lr: 0.0010\n",
      "Epoch 134/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0058 - mae: 0.0058 - mse: 6.9937e-05 - val_loss: 0.0146 - val_mae: 0.0146 - val_mse: 2.8687e-04 - lr: 0.0010\n",
      "Epoch 135/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0058 - mae: 0.0058 - mse: 5.8546e-05 - val_loss: 0.0185 - val_mae: 0.0185 - val_mse: 5.4730e-04 - lr: 0.0010\n",
      "Epoch 136/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0099 - mae: 0.0099 - mse: 1.4442e-04 - val_loss: 0.0147 - val_mae: 0.0147 - val_mse: 3.1797e-04 - lr: 0.0010\n",
      "Epoch 137/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0128 - mae: 0.0128 - mse: 1.7680e-04 - val_loss: 0.0229 - val_mae: 0.0229 - val_mse: 7.4863e-04 - lr: 0.0010\n",
      "Epoch 138/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0119 - mae: 0.0119 - mse: 1.7213e-04 - val_loss: 0.0143 - val_mae: 0.0143 - val_mse: 2.6608e-04 - lr: 0.0010\n",
      "Epoch 139/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0072 - mae: 0.0072 - mse: 7.2471e-05 - val_loss: 0.0204 - val_mae: 0.0204 - val_mse: 6.2726e-04 - lr: 0.0010\n",
      "Epoch 140/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0068 - mae: 0.0068 - mse: 7.3048e-05 - val_loss: 0.0135 - val_mae: 0.0135 - val_mse: 2.4042e-04 - lr: 0.0010\n",
      "Epoch 141/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0074 - mae: 0.0074 - mse: 7.0525e-05 - val_loss: 0.0287 - val_mae: 0.0287 - val_mse: 0.0010 - lr: 0.0010\n",
      "Epoch 142/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0131 - mae: 0.0131 - mse: 2.1050e-04 - val_loss: 0.0128 - val_mae: 0.0128 - val_mse: 2.2572e-04 - lr: 0.0010\n",
      "Epoch 143/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0151 - mae: 0.0151 - mse: 2.4663e-04 - val_loss: 0.0138 - val_mae: 0.0138 - val_mse: 2.4995e-04 - lr: 0.0010\n",
      "Epoch 144/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0098 - mae: 0.0098 - mse: 1.5748e-04 - val_loss: 0.0348 - val_mae: 0.0348 - val_mse: 0.0014 - lr: 0.0010\n",
      "Epoch 145/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0184 - mae: 0.0184 - mse: 4.2450e-04 - val_loss: 0.0242 - val_mae: 0.0242 - val_mse: 8.4524e-04 - lr: 0.0010\n",
      "Epoch 146/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0317 - mae: 0.0317 - mse: 0.0011 - val_loss: 0.0278 - val_mae: 0.0278 - val_mse: 0.0011 - lr: 0.0010\n",
      "Epoch 147/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0263 - mae: 0.0263 - mse: 8.4850e-04 - val_loss: 0.0357 - val_mae: 0.0357 - val_mse: 0.0016 - lr: 0.0010\n",
      "Epoch 148/1000\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0269 - mae: 0.0269 - mse: 7.6268e-04\n",
      "Epoch 00148: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0281 - mae: 0.0281 - mse: 8.2957e-04 - val_loss: 0.0328 - val_mae: 0.0328 - val_mse: 0.0014 - lr: 0.0010\n",
      "Epoch 149/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0239 - mae: 0.0239 - mse: 6.1303e-04 - val_loss: 0.0250 - val_mae: 0.0250 - val_mse: 9.2276e-04 - lr: 1.0000e-04\n",
      "Epoch 150/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0162 - mae: 0.0162 - mse: 3.1539e-04 - val_loss: 0.0181 - val_mae: 0.0181 - val_mse: 4.2684e-04 - lr: 1.0000e-04\n",
      "Epoch 151/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0052 - mae: 0.0052 - mse: 5.7310e-05 - val_loss: 0.0158 - val_mae: 0.0158 - val_mse: 3.3526e-04 - lr: 1.0000e-04\n",
      "Epoch 152/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0111 - mae: 0.0111 - mse: 1.6278e-04 - val_loss: 0.0172 - val_mae: 0.0172 - val_mse: 4.5984e-04 - lr: 1.0000e-04\n",
      "Epoch 153/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0164 - mae: 0.0164 - mse: 3.0788e-04 - val_loss: 0.0166 - val_mae: 0.0166 - val_mse: 4.2593e-04 - lr: 1.0000e-04\n",
      "Epoch 154/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0145 - mae: 0.0145 - mse: 2.4695e-04 - val_loss: 0.0153 - val_mae: 0.0153 - val_mse: 3.0947e-04 - lr: 1.0000e-04\n",
      "Epoch 155/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0078 - mae: 0.0078 - mse: 8.8409e-05 - val_loss: 0.0176 - val_mae: 0.0176 - val_mse: 4.0505e-04 - lr: 1.0000e-04\n",
      "Epoch 156/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0058 - mae: 0.0058 - mse: 7.1795e-05 - val_loss: 0.0195 - val_mae: 0.0195 - val_mse: 5.9778e-04 - lr: 1.0000e-04\n",
      "Epoch 157/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0107 - mae: 0.0107 - mse: 1.5566e-04 - val_loss: 0.0189 - val_mae: 0.0189 - val_mse: 5.5127e-04 - lr: 1.0000e-04\n",
      "Epoch 158/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0086 - mae: 0.0086 - mse: 1.1398e-04 - val_loss: 0.0167 - val_mae: 0.0167 - val_mse: 3.5093e-04 - lr: 1.0000e-04\n",
      "Epoch 159/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0049 - mae: 0.0049 - mse: 5.3313e-05 - val_loss: 0.0145 - val_mae: 0.0145 - val_mse: 2.7599e-04 - lr: 1.0000e-04\n",
      "Epoch 160/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0068 - mae: 0.0068 - mse: 6.8221e-05 - val_loss: 0.0143 - val_mae: 0.0143 - val_mse: 2.6710e-04 - lr: 1.0000e-04\n",
      "Epoch 161/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0064 - mae: 0.0064 - mse: 6.0999e-05 - val_loss: 0.0154 - val_mae: 0.0154 - val_mse: 2.9596e-04 - lr: 1.0000e-04\n",
      "Epoch 162/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0041 - mae: 0.0041 - mse: 4.0975e-05 - val_loss: 0.0165 - val_mae: 0.0165 - val_mse: 3.8096e-04 - lr: 1.0000e-04\n",
      "Epoch 163/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0053 - mae: 0.0053 - mse: 6.0821e-05 - val_loss: 0.0159 - val_mae: 0.0159 - val_mse: 3.4395e-04 - lr: 1.0000e-04\n",
      "Epoch 164/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0044 - mae: 0.0044 - mse: 4.8884e-05 - val_loss: 0.0145 - val_mae: 0.0145 - val_mse: 2.6502e-04 - lr: 1.0000e-04\n",
      "Epoch 165/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0041 - mae: 0.0041 - mse: 3.8458e-05 - val_loss: 0.0146 - val_mae: 0.0146 - val_mse: 2.7090e-04 - lr: 1.0000e-04\n",
      "Epoch 166/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0035 - mae: 0.0035 - mse: 3.5309e-05 - val_loss: 0.0155 - val_mae: 0.0155 - val_mse: 3.3865e-04 - lr: 1.0000e-04\n",
      "Epoch 167/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0040 - mae: 0.0040 - mse: 4.4586e-05 - val_loss: 0.0156 - val_mae: 0.0156 - val_mse: 3.5554e-04 - lr: 1.0000e-04\n",
      "Epoch 168/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0041 - mae: 0.0041 - mse: 4.4286e-05 - val_loss: 0.0149 - val_mae: 0.0149 - val_mse: 3.0152e-04 - lr: 1.0000e-04\n",
      "Epoch 169/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0034 - mae: 0.0034 - mse: 3.6456e-05 - val_loss: 0.0144 - val_mae: 0.0144 - val_mse: 2.7283e-04 - lr: 1.0000e-04\n",
      "Epoch 170/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0036 - mae: 0.0036 - mse: 3.5169e-05 - val_loss: 0.0150 - val_mae: 0.0150 - val_mse: 3.1212e-04 - lr: 1.0000e-04\n",
      "Epoch 171/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0033 - mae: 0.0033 - mse: 3.4525e-05 - val_loss: 0.0154 - val_mae: 0.0154 - val_mse: 3.4162e-04 - lr: 1.0000e-04\n",
      "Epoch 172/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0033 - mae: 0.0033 - mse: 3.5763e-05 - val_loss: 0.0153 - val_mae: 0.0153 - val_mse: 3.2841e-04 - lr: 1.0000e-04\n",
      "Epoch 173/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0032 - mae: 0.0032 - mse: 3.4688e-05 - val_loss: 0.0154 - val_mae: 0.0154 - val_mse: 3.3665e-04 - lr: 1.0000e-04\n",
      "Epoch 174/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0031 - mae: 0.0031 - mse: 3.3644e-05 - val_loss: 0.0155 - val_mae: 0.0155 - val_mse: 3.3501e-04 - lr: 1.0000e-04\n",
      "Epoch 175/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0032 - mae: 0.0032 - mse: 3.3039e-05 - val_loss: 0.0159 - val_mae: 0.0159 - val_mse: 3.6325e-04 - lr: 1.0000e-04\n",
      "Epoch 176/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0031 - mae: 0.0031 - mse: 3.4780e-05 - val_loss: 0.0161 - val_mae: 0.0161 - val_mse: 3.6981e-04 - lr: 1.0000e-04\n",
      "Epoch 177/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0031 - mae: 0.0031 - mse: 3.4390e-05 - val_loss: 0.0158 - val_mae: 0.0158 - val_mse: 3.4317e-04 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0032 - mae: 0.0032 - mse: 3.2274e-05 - val_loss: 0.0160 - val_mae: 0.0160 - val_mse: 3.5298e-04 - lr: 1.0000e-04\n",
      "Epoch 179/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0031 - mae: 0.0031 - mse: 3.2977e-05 - val_loss: 0.0165 - val_mae: 0.0165 - val_mse: 3.9565e-04 - lr: 1.0000e-04\n",
      "Epoch 180/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0033 - mae: 0.0033 - mse: 3.7139e-05 - val_loss: 0.0160 - val_mae: 0.0160 - val_mse: 3.4607e-04 - lr: 1.0000e-04\n",
      "Epoch 181/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0033 - mae: 0.0033 - mse: 3.3739e-05 - val_loss: 0.0159 - val_mae: 0.0159 - val_mse: 3.3348e-04 - lr: 1.0000e-04\n",
      "Epoch 182/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0032 - mae: 0.0032 - mse: 3.4165e-05 - val_loss: 0.0163 - val_mae: 0.0163 - val_mse: 3.6829e-04 - lr: 1.0000e-04\n",
      "Epoch 183/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0031 - mae: 0.0031 - mse: 3.6633e-05 - val_loss: 0.0160 - val_mae: 0.0160 - val_mse: 3.4032e-04 - lr: 1.0000e-04\n",
      "Epoch 184/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0031 - mae: 0.0031 - mse: 3.4358e-05 - val_loss: 0.0160 - val_mae: 0.0160 - val_mse: 3.3926e-04 - lr: 1.0000e-04\n",
      "Epoch 185/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0031 - mae: 0.0031 - mse: 3.5691e-05 - val_loss: 0.0164 - val_mae: 0.0164 - val_mse: 3.6906e-04 - lr: 1.0000e-04\n",
      "Epoch 186/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0031 - mae: 0.0031 - mse: 3.7748e-05 - val_loss: 0.0160 - val_mae: 0.0160 - val_mse: 3.3668e-04 - lr: 1.0000e-04\n",
      "Epoch 187/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0033 - mae: 0.0033 - mse: 3.5910e-05 - val_loss: 0.0161 - val_mae: 0.0161 - val_mse: 3.4062e-04 - lr: 1.0000e-04\n",
      "Epoch 188/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0031 - mae: 0.0031 - mse: 3.4161e-05 - val_loss: 0.0167 - val_mae: 0.0167 - val_mse: 3.7939e-04 - lr: 1.0000e-04\n",
      "Epoch 189/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0031 - mae: 0.0031 - mse: 3.6975e-05 - val_loss: 0.0162 - val_mae: 0.0162 - val_mse: 3.4311e-04 - lr: 1.0000e-04\n",
      "Epoch 190/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0032 - mae: 0.0032 - mse: 3.3472e-05 - val_loss: 0.0159 - val_mae: 0.0159 - val_mse: 3.2764e-04 - lr: 1.0000e-04\n",
      "Epoch 191/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0036 - mae: 0.0036 - mse: 3.4850e-05 - val_loss: 0.0167 - val_mae: 0.0167 - val_mse: 3.8138e-04 - lr: 1.0000e-04\n",
      "Epoch 192/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0030 - mae: 0.0030 - mse: 3.6794e-05 - val_loss: 0.0169 - val_mae: 0.0169 - val_mse: 3.9594e-04 - lr: 1.0000e-04\n",
      "Epoch 193/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0031 - mae: 0.0031 - mse: 3.6079e-05 - val_loss: 0.0163 - val_mae: 0.0163 - val_mse: 3.5022e-04 - lr: 1.0000e-04\n",
      "Epoch 194/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0031 - mae: 0.0031 - mse: 3.3024e-05 - val_loss: 0.0167 - val_mae: 0.0167 - val_mse: 3.8103e-04 - lr: 1.0000e-04\n",
      "Epoch 195/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0030 - mae: 0.0030 - mse: 3.5119e-05 - val_loss: 0.0170 - val_mae: 0.0170 - val_mse: 4.0793e-04 - lr: 1.0000e-04\n",
      "Epoch 196/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0033 - mae: 0.0033 - mse: 3.8125e-05 - val_loss: 0.0166 - val_mae: 0.0166 - val_mse: 3.7417e-04 - lr: 1.0000e-04\n",
      "Epoch 197/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0029 - mae: 0.0029 - mse: 3.2926e-05 - val_loss: 0.0167 - val_mae: 0.0167 - val_mse: 3.7509e-04 - lr: 1.0000e-04\n",
      "Epoch 198/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0029 - mae: 0.0029 - mse: 3.2467e-05 - val_loss: 0.0171 - val_mae: 0.0171 - val_mse: 4.0946e-04 - lr: 1.0000e-04\n",
      "Epoch 199/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0030 - mae: 0.0030 - mse: 3.6946e-05 - val_loss: 0.0172 - val_mae: 0.0172 - val_mse: 4.1169e-04 - lr: 1.0000e-04\n",
      "Epoch 200/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0029 - mae: 0.0029 - mse: 3.5569e-05 - val_loss: 0.0167 - val_mae: 0.0167 - val_mse: 3.7178e-04 - lr: 1.0000e-04\n",
      "Epoch 201/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0031 - mae: 0.0031 - mse: 3.2224e-05 - val_loss: 0.0171 - val_mae: 0.0171 - val_mse: 4.0439e-04 - lr: 1.0000e-04\n",
      "Epoch 202/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0030 - mae: 0.0030 - mse: 3.5258e-05 - val_loss: 0.0172 - val_mae: 0.0172 - val_mse: 4.1015e-04 - lr: 1.0000e-04\n",
      "Epoch 203/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0032 - mae: 0.0032 - mse: 3.6720e-05 - val_loss: 0.0167 - val_mae: 0.0167 - val_mse: 3.7542e-04 - lr: 1.0000e-04\n",
      "Epoch 204/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0029 - mae: 0.0029 - mse: 3.3338e-05 - val_loss: 0.0171 - val_mae: 0.0171 - val_mse: 4.1214e-04 - lr: 1.0000e-04\n",
      "Epoch 205/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0031 - mae: 0.0031 - mse: 3.6516e-05 - val_loss: 0.0169 - val_mae: 0.0169 - val_mse: 3.9572e-04 - lr: 1.0000e-04\n",
      "Epoch 206/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0029 - mae: 0.0029 - mse: 3.3598e-05 - val_loss: 0.0168 - val_mae: 0.0168 - val_mse: 3.7931e-04 - lr: 1.0000e-04\n",
      "Epoch 207/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0029 - mae: 0.0029 - mse: 3.2647e-05 - val_loss: 0.0170 - val_mae: 0.0170 - val_mse: 4.0231e-04 - lr: 1.0000e-04\n",
      "Epoch 208/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0030 - mae: 0.0030 - mse: 3.4673e-05 - val_loss: 0.0170 - val_mae: 0.0170 - val_mse: 4.0070e-04 - lr: 1.0000e-04\n",
      "Epoch 209/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0030 - mae: 0.0030 - mse: 3.2983e-05 - val_loss: 0.0165 - val_mae: 0.0165 - val_mse: 3.5970e-04 - lr: 1.0000e-04\n",
      "Epoch 210/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0031 - mae: 0.0031 - mse: 3.3725e-05 - val_loss: 0.0168 - val_mae: 0.0168 - val_mse: 3.7873e-04 - lr: 1.0000e-04\n",
      "Epoch 211/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0028 - mae: 0.0028 - mse: 3.2237e-05 - val_loss: 0.0170 - val_mae: 0.0170 - val_mse: 3.9037e-04 - lr: 1.0000e-04\n",
      "Epoch 212/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0028 - mae: 0.0028 - mse: 3.2931e-05 - val_loss: 0.0173 - val_mae: 0.0173 - val_mse: 4.0990e-04 - lr: 1.0000e-04\n",
      "Epoch 213/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0029 - mae: 0.0029 - mse: 3.5211e-05 - val_loss: 0.0170 - val_mae: 0.0170 - val_mse: 3.8506e-04 - lr: 1.0000e-04\n",
      "Epoch 214/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0028 - mae: 0.0028 - mse: 3.2151e-05 - val_loss: 0.0169 - val_mae: 0.0169 - val_mse: 3.8140e-04 - lr: 1.0000e-04\n",
      "Epoch 215/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0028 - mae: 0.0028 - mse: 3.2440e-05 - val_loss: 0.0174 - val_mae: 0.0174 - val_mse: 4.2448e-04 - lr: 1.0000e-04\n",
      "Epoch 216/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0030 - mae: 0.0030 - mse: 3.5954e-05 - val_loss: 0.0170 - val_mae: 0.0170 - val_mse: 3.9188e-04 - lr: 1.0000e-04\n",
      "Epoch 217/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0027 - mae: 0.0027 - mse: 3.1713e-05 - val_loss: 0.0166 - val_mae: 0.0166 - val_mse: 3.6353e-04 - lr: 1.0000e-04\n",
      "Epoch 218/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0033 - mae: 0.0033 - mse: 3.2405e-05 - val_loss: 0.0169 - val_mae: 0.0169 - val_mse: 3.8655e-04 - lr: 1.0000e-04\n",
      "Epoch 219/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0028 - mae: 0.0028 - mse: 3.1346e-05 - val_loss: 0.0176 - val_mae: 0.0176 - val_mse: 4.4872e-04 - lr: 1.0000e-04\n",
      "Epoch 220/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0035 - mae: 0.0035 - mse: 3.9811e-05 - val_loss: 0.0170 - val_mae: 0.0170 - val_mse: 3.9783e-04 - lr: 1.0000e-04\n",
      "Epoch 221/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0031 - mae: 0.0031 - mse: 3.3818e-05 - val_loss: 0.0166 - val_mae: 0.0166 - val_mse: 3.6194e-04 - lr: 1.0000e-04\n",
      "Epoch 222/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0030 - mae: 0.0030 - mse: 3.1472e-05 - val_loss: 0.0175 - val_mae: 0.0175 - val_mse: 4.4616e-04 - lr: 1.0000e-04\n",
      "Epoch 223/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0038 - mae: 0.0038 - mse: 4.2028e-05 - val_loss: 0.0172 - val_mae: 0.0172 - val_mse: 4.1536e-04 - lr: 1.0000e-04\n",
      "Epoch 224/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0030 - mae: 0.0030 - mse: 3.5120e-05 - val_loss: 0.0163 - val_mae: 0.0163 - val_mse: 3.4146e-04 - lr: 1.0000e-04\n",
      "Epoch 225/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0034 - mae: 0.0034 - mse: 3.1977e-05 - val_loss: 0.0171 - val_mae: 0.0171 - val_mse: 4.0563e-04 - lr: 1.0000e-04\n",
      "Epoch 226/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0033 - mae: 0.0033 - mse: 3.8375e-05 - val_loss: 0.0173 - val_mae: 0.0173 - val_mse: 4.2272e-04 - lr: 1.0000e-04\n",
      "Epoch 227/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0034 - mae: 0.0034 - mse: 3.7011e-05 - val_loss: 0.0162 - val_mae: 0.0162 - val_mse: 3.3732e-04 - lr: 1.0000e-04\n",
      "Epoch 228/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0035 - mae: 0.0035 - mse: 3.2168e-05 - val_loss: 0.0167 - val_mae: 0.0167 - val_mse: 3.7129e-04 - lr: 1.0000e-04\n",
      "Epoch 229/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0030 - mae: 0.0030 - mse: 3.2043e-05 - val_loss: 0.0171 - val_mae: 0.0171 - val_mse: 4.0474e-04 - lr: 1.0000e-04\n",
      "Epoch 230/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0028 - mae: 0.0028 - mse: 3.2854e-05 - val_loss: 0.0168 - val_mae: 0.0168 - val_mse: 3.8134e-04 - lr: 1.0000e-04\n",
      "Epoch 231/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0028 - mae: 0.0028 - mse: 3.0778e-05 - val_loss: 0.0170 - val_mae: 0.0170 - val_mse: 3.9951e-04 - lr: 1.0000e-04\n",
      "Epoch 232/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0027 - mae: 0.0027 - mse: 3.2115e-05 - val_loss: 0.0172 - val_mae: 0.0172 - val_mse: 4.1540e-04 - lr: 1.0000e-04\n",
      "Epoch 233/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0028 - mae: 0.0028 - mse: 3.3307e-05 - val_loss: 0.0168 - val_mae: 0.0168 - val_mse: 3.7293e-04 - lr: 1.0000e-04\n",
      "Epoch 234/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0028 - mae: 0.0028 - mse: 3.1064e-05 - val_loss: 0.0169 - val_mae: 0.0169 - val_mse: 3.8449e-04 - lr: 1.0000e-04\n",
      "Epoch 235/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0027 - mae: 0.0027 - mse: 3.1631e-05 - val_loss: 0.0175 - val_mae: 0.0175 - val_mse: 4.2526e-04 - lr: 1.0000e-04\n",
      "Epoch 236/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0032 - mae: 0.0032 - mse: 3.7141e-05 - val_loss: 0.0173 - val_mae: 0.0173 - val_mse: 4.0957e-04 - lr: 1.0000e-04\n",
      "Epoch 237/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0027 - mae: 0.0027 - mse: 3.1702e-05 - val_loss: 0.0168 - val_mae: 0.0168 - val_mse: 3.6228e-04 - lr: 1.0000e-04\n",
      "Epoch 238/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0032 - mae: 0.0032 - mse: 3.1138e-05 - val_loss: 0.0176 - val_mae: 0.0176 - val_mse: 4.2892e-04 - lr: 1.0000e-04\n",
      "Epoch 239/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0033 - mae: 0.0033 - mse: 3.7255e-05 - val_loss: 0.0175 - val_mae: 0.0175 - val_mse: 4.1559e-04 - lr: 1.0000e-04\n",
      "Epoch 240/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0032 - mae: 0.0032 - mse: 3.5890e-05 - val_loss: 0.0166 - val_mae: 0.0166 - val_mse: 3.5296e-04 - lr: 1.0000e-04\n",
      "Epoch 241/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0034 - mae: 0.0034 - mse: 3.3250e-05 - val_loss: 0.0173 - val_mae: 0.0173 - val_mse: 4.0528e-04 - lr: 1.0000e-04\n",
      "Epoch 242/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0029 - mae: 0.0029 - mse: 3.4626e-05 - val_loss: 0.0171 - val_mae: 0.0171 - val_mse: 3.9542e-04 - lr: 1.0000e-04\n",
      "Epoch 243/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0028 - mae: 0.0028 - mse: 3.3364e-05 - val_loss: 0.0167 - val_mae: 0.0167 - val_mse: 3.6655e-04 - lr: 1.0000e-04\n",
      "Epoch 244/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0028 - mae: 0.0028 - mse: 3.1882e-05 - val_loss: 0.0173 - val_mae: 0.0173 - val_mse: 4.1908e-04 - lr: 1.0000e-04\n",
      "Epoch 245/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0030 - mae: 0.0030 - mse: 3.5063e-05 - val_loss: 0.0168 - val_mae: 0.0168 - val_mse: 3.7535e-04 - lr: 1.0000e-04\n",
      "Epoch 246/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0029 - mae: 0.0029 - mse: 3.1567e-05 - val_loss: 0.0166 - val_mae: 0.0166 - val_mse: 3.6879e-04 - lr: 1.0000e-04\n",
      "Epoch 247/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0027 - mae: 0.0027 - mse: 3.1192e-05 - val_loss: 0.0171 - val_mae: 0.0171 - val_mse: 4.1491e-04 - lr: 1.0000e-04\n",
      "Epoch 248/1000\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0022 - mae: 0.0022 - mse: 1.8201e-05\n",
      "Epoch 00248: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0029 - mae: 0.0029 - mse: 3.2479e-05 - val_loss: 0.0165 - val_mae: 0.0165 - val_mse: 3.6613e-04 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mae\",optimizer = tf.keras.optimizers.Adam(), metrics=[\"mae\",\"mse\"])\n",
    "history = model.fit(final_x_zeros_scaled[:43],final_y_zeros[:43],\n",
    "                    epochs = 1000,\n",
    "                    validation_data = (final_x_zeros_scaled[43:], final_y_zeros[43:]),\n",
    "                   callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", \n",
    "                                                        patience=200, \n",
    "                                                        restore_best_weights=True),\n",
    "                      tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", \n",
    "                                                           patience=100, \n",
    "                                                           verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "809146ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([794.7976 , 796.802  , 789.7172 , 794.16956, 808.69275, 816.62695,\n",
       "       805.85   , 797.77545, 763.6633 , 782.0082 , 791.0225 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = tf.squeeze(model.predict(final_x_zeros_scaled[43:])).numpy()\n",
    "preds = preds*k.values[0]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cfd3d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.65093994140625"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = sum(abs(preds-(tf.squeeze(final_y_zeros[43:].to_numpy()).numpy())*k.values[0]))\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08b6ddcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d461ba25b0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(final_y_zeros.index[43:], (tf.squeeze(final_y_zeros[43:].to_numpy()).numpy())*k.values[0])\n",
    "plt.plot(final_y_zeros.index[43:], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "693e357d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_3_layer_call_fn, gru_cell_3_layer_call_and_return_conditional_losses, gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: GRU_icici\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: GRU_icici\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001D68D5DFA00> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001D68D674D90> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001D68C454E50> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model.save(\"GRU_icici\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa6a409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e013a9af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2324bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3615c425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b45f12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07ff8d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78078f83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3e61d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b2194f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3437ee4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ws_env",
   "language": "python",
   "name": "ws_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
