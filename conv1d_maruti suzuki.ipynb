{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1840cd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "df_stock = pd.read_csv(\"maruti_suzuki/MARUTI.NS.csv\",\n",
    "                 parse_dates = [\"Date\"],\n",
    "                 index_col = [\"Date\"])\n",
    "df_posts = pd.read_excel(\"maruti_suzuki/maruti_suzuki_final_posts.xlsx\")\n",
    "# removing the unnecessary columns\n",
    "df_posts.drop([\"Unnamed: 0\"], axis=1,inplace=True)\n",
    "# removing spam posts\n",
    "df_posts = df_posts[df_posts.Spam==0.0]\n",
    "df_posts.drop([\"Spam\"],axis=1,inplace=True)\n",
    "# sliding a window of 7 days and adding all the TIs\n",
    "from stock_helper import prepare_data\n",
    "x,y = prepare_data(df_stock)\n",
    "final_x = x[np.datetime64(\"2021-11-13\"):]\n",
    "final_y = y[np.datetime64(\"2021-11-13\"):]\n",
    "# reversing the posts data\n",
    "df_posts = df_posts[::-1]\n",
    "final_posts = df_posts[7:]\n",
    "# loading the sentiment analysis model\n",
    "sent_model = tf.keras.models.load_model(\"final_bert\")\n",
    "# removing duplicates from the data\n",
    "final_posts.drop_duplicates(subset=['Messages'])\n",
    "# calculating the sentiments score\n",
    "sentiments = []\n",
    "prev = np.datetime64(\"2015-11-12 21:31:26\")\n",
    "for i in final_y.index:\n",
    "    total=0\n",
    "    cnt=0\n",
    "    for j in final_posts.itertuples():\n",
    "        _,msg,time = j\n",
    "        if np.datetime64(time)<np.datetime64(i) and np.datetime64(time)>prev:\n",
    "            total += tf.squeeze(sent_model.predict([msg])).numpy()\n",
    "            cnt+=1\n",
    "    prev = np.datetime64(i)\n",
    "    if(cnt==0):\n",
    "        sentiments.append(0)\n",
    "    else:\n",
    "        sentiments.append(total/cnt)\n",
    "# getting indices where sentiments score is 0\n",
    "zero_index = []\n",
    "for i,j in enumerate(sentiments):\n",
    "    if(j==0):\n",
    "        zero_index.append(i)\n",
    "# removing all the zero values indices\n",
    "sentiments = np.delete(sentiments,zero_index)\n",
    "final_x_zeros = final_x.copy()\n",
    "final_y_zeros = final_y.copy()\n",
    "final_y_zeros = final_y_zeros.to_frame()\n",
    "final_x_zeros['removal_assist'] = np.arange(0,len(final_x),1)\n",
    "final_y_zeros['removal_assist'] = np.arange(0,len(final_x),1)\n",
    "final_y_zeros = final_y_zeros[final_y_zeros.removal_assist.isin(zero_index)==False]\n",
    "final_x_zeros = final_x_zeros[final_x_zeros.removal_assist.isin(zero_index)==False]\n",
    "# removing the added helper column\n",
    "final_x_zeros.drop([\"removal_assist\"], axis=1,inplace=True)\n",
    "final_y_zeros.drop([\"removal_assist\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45369fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 71, 1)]           0         \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 71, 64)            256       \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPooling  (None, 35, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 35, 64)            12352     \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPooling  (None, 17, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " global_max_pooling1d_3 (Glo  (None, 64)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,673\n",
      "Trainable params: 12,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "inputs = tf.keras.Input(shape=(71,1), name=\"inputs\")\n",
    "x = tf.keras.layers.Conv1D(64, 3, activation=\"relu\", padding=\"causal\")(inputs)\n",
    "x = tf.keras.layers.MaxPooling1D()(x)\n",
    "x = tf.keras.layers.Conv1D(64, 3, activation=\"relu\", padding=\"causal\")(x)\n",
    "x = tf.keras.layers.MaxPooling1D()(x)\n",
    "x = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "model = tf.keras.models.Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06b904bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 693ms/step - loss: 164.8210 - mae: 164.8210 - mse: 55453.7305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[164.8209686279297, 164.8209686279297, 55453.73046875]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nbeats = tf.keras.models.load_model(\"nbeats_maruti suzuki\")\n",
    "model_nbeats.evaluate(final_x_zeros[50:],final_y_zeros[50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e9eb79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2/2 [==============================] - 1s 186ms/step - loss: 8310.7383 - mae: 8310.7383 - mse: 69434632.0000 - val_loss: 7893.9048 - val_mae: 7893.9048 - val_mse: 62330960.0000 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 6665.4575 - mae: 6665.4575 - mse: 44742888.0000 - val_loss: 6190.3945 - val_mae: 6190.3945 - val_mse: 38337744.0000 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 5133.6436 - mae: 5133.6436 - mse: 26671494.0000 - val_loss: 4578.5156 - val_mae: 4578.5156 - val_mse: 20980694.0000 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 3662.8525 - mae: 3662.8525 - mse: 13684516.0000 - val_loss: 3000.0515 - val_mae: 3000.0515 - val_mse: 9020799.0000 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 2217.4780 - mae: 2217.4780 - mse: 5216051.0000 - val_loss: 1435.2510 - val_mae: 1435.2510 - val_mse: 2083841.0000 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 805.9724 - mae: 805.9724 - mse: 823806.3750 - val_loss: 189.6569 - val_mae: 189.6569 - val_mse: 42496.9766 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 593.5967 - mae: 593.5967 - mse: 495348.5625 - val_loss: 1065.4331 - val_mae: 1065.4331 - val_mse: 1167416.5000 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1309.5040 - mae: 1309.5040 - mse: 1833174.8750 - val_loss: 1319.5875 - val_mae: 1319.5875 - val_mse: 1774262.6250 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1453.9214 - mae: 1453.9214 - mse: 2226712.2500 - val_loss: 1095.5333 - val_mae: 1095.5333 - val_mse: 1232093.8750 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1190.8888 - mae: 1190.8888 - mse: 1547709.7500 - val_loss: 560.3273 - val_mae: 560.3273 - val_mse: 343668.9062 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 666.5146 - mae: 666.5146 - mse: 581119.6250 - val_loss: 167.8255 - val_mae: 167.8255 - val_mse: 54470.8555 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 299.5234 - mae: 299.5234 - mse: 128207.0781 - val_loss: 793.0464 - val_mae: 793.0464 - val_mse: 654420.5625 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 538.9209 - mae: 538.9210 - mse: 391946.4062 - val_loss: 1050.9364 - val_mae: 1050.9364 - val_mse: 1129059.6250 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 691.8749 - mae: 691.8749 - mse: 593898.5000 - val_loss: 963.1307 - val_mae: 963.1307 - val_mse: 952362.8125 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 581.9969 - mae: 581.9969 - mse: 450993.1250 - val_loss: 634.3625 - val_mae: 634.3625 - val_mse: 428087.0000 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 342.6992 - mae: 342.6992 - mse: 175368.3594 - val_loss: 199.9951 - val_mae: 199.9951 - val_mse: 66967.2500 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 315.5041 - mae: 315.5041 - mse: 147579.1875 - val_loss: 193.2594 - val_mae: 193.2594 - val_mse: 43256.5664 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 431.1269 - mae: 431.1269 - mse: 272881.9375 - val_loss: 225.6411 - val_mae: 225.6411 - val_mse: 57721.7617 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 429.1211 - mae: 429.1211 - mse: 271763.9062 - val_loss: 113.8574 - val_mae: 113.8574 - val_mse: 27533.9824 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 321.1558 - mae: 321.1558 - mse: 149589.4375 - val_loss: 304.4988 - val_mae: 304.4988 - val_mse: 118836.1953 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 283.9689 - mae: 283.9689 - mse: 123570.0781 - val_loss: 515.2873 - val_mae: 515.2873 - val_mse: 290910.4375 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 318.9485 - mae: 318.9485 - mse: 157145.4531 - val_loss: 515.5057 - val_mae: 515.5057 - val_mse: 291060.7188 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 309.2308 - mae: 309.2308 - mse: 152064.0625 - val_loss: 387.8141 - val_mae: 387.8141 - val_mse: 176016.3750 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 275.1231 - mae: 275.1231 - mse: 116325.0078 - val_loss: 226.9854 - val_mae: 226.9854 - val_mse: 77585.0156 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 286.6778 - mae: 286.6778 - mse: 118153.4766 - val_loss: 147.2891 - val_mae: 147.2891 - val_mse: 46267.0742 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 299.0125 - mae: 299.0125 - mse: 128281.3984 - val_loss: 177.8018 - val_mae: 177.8018 - val_mse: 57912.5195 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 283.5761 - mae: 283.5761 - mse: 117613.7422 - val_loss: 294.8908 - val_mae: 294.8908 - val_mse: 113054.0078 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 276.1838 - mae: 276.1838 - mse: 115099.0078 - val_loss: 395.6350 - val_mae: 395.6350 - val_mse: 182498.2344 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 274.0350 - mae: 274.0350 - mse: 120495.3984 - val_loss: 389.5299 - val_mae: 389.5299 - val_mse: 177919.6406 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 270.9966 - mae: 270.9966 - mse: 116813.8594 - val_loss: 332.7632 - val_mae: 332.7632 - val_mse: 137130.0156 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 273.2265 - mae: 273.2265 - mse: 112832.7734 - val_loss: 265.4534 - val_mae: 265.4534 - val_mse: 97013.6875 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 272.8063 - mae: 272.8063 - mse: 109723.1719 - val_loss: 267.5780 - val_mae: 267.5780 - val_mse: 98114.0234 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 266.8054 - mae: 266.8054 - mse: 107115.7812 - val_loss: 336.7822 - val_mae: 336.7822 - val_mse: 139730.7344 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 264.9246 - mae: 264.9246 - mse: 110419.7422 - val_loss: 398.1296 - val_mae: 398.1296 - val_mse: 184631.9219 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 273.2500 - mae: 273.2500 - mse: 120529.2031 - val_loss: 381.0614 - val_mae: 381.0614 - val_mse: 171350.0781 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 264.8134 - mae: 264.8134 - mse: 113221.8281 - val_loss: 292.5154 - val_mae: 292.5154 - val_mse: 111910.8516 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 265.3592 - mae: 265.3592 - mse: 106330.8125 - val_loss: 220.7950 - val_mae: 220.7950 - val_mse: 75262.3438 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 272.0728 - mae: 272.0728 - mse: 108899.3594 - val_loss: 229.9647 - val_mae: 229.9647 - val_mse: 79350.3438 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 266.7491 - mae: 266.7491 - mse: 106854.5000 - val_loss: 306.0337 - val_mae: 306.0337 - val_mse: 119905.9375 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 267.5040 - mae: 267.5040 - mse: 110261.0000 - val_loss: 378.3158 - val_mae: 378.3158 - val_mse: 169245.2500 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 265.1916 - mae: 265.1916 - mse: 113344.3594 - val_loss: 330.0823 - val_mae: 330.0823 - val_mse: 136323.5469 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 264.0169 - mae: 264.0169 - mse: 105155.0391 - val_loss: 250.4326 - val_mae: 250.4326 - val_mse: 90367.9609 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 260.6480 - mae: 260.6480 - mse: 102668.5781 - val_loss: 223.0188 - val_mae: 223.0188 - val_mse: 77988.8672 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 259.2742 - mae: 259.2742 - mse: 102856.2812 - val_loss: 306.6174 - val_mae: 306.6174 - val_mse: 121985.3203 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 258.0435 - mae: 258.0435 - mse: 104514.8828 - val_loss: 385.2404 - val_mae: 385.2404 - val_mse: 176111.7656 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 260.8630 - mae: 260.8630 - mse: 110889.4531 - val_loss: 297.4549 - val_mae: 297.4549 - val_mse: 116616.8203 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 257.4402 - mae: 257.4402 - mse: 102654.6562 - val_loss: 198.2677 - val_mae: 198.2677 - val_mse: 67879.8828 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 267.0602 - mae: 267.0602 - mse: 106773.3516 - val_loss: 238.8842 - val_mae: 238.8842 - val_mse: 86429.7578 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 254.4079 - mae: 254.4079 - mse: 100851.8594 - val_loss: 242.3890 - val_mae: 242.3890 - val_mse: 88345.4375 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 248.7501 - mae: 248.7501 - mse: 98489.6484 - val_loss: 251.4715 - val_mae: 251.4715 - val_mse: 92820.6172 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 247.1237 - mae: 247.1237 - mse: 96657.8984 - val_loss: 291.6786 - val_mae: 291.6786 - val_mse: 114513.0234 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 246.6464 - mae: 246.6464 - mse: 98235.1562 - val_loss: 299.9418 - val_mae: 299.9418 - val_mse: 119376.1797 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 248.6756 - mae: 248.6756 - mse: 98993.3203 - val_loss: 284.7788 - val_mae: 284.7788 - val_mse: 110471.5000 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 245.6851 - mae: 245.6851 - mse: 97654.5312 - val_loss: 255.7051 - val_mae: 255.7051 - val_mse: 94770.4453 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 242.3207 - mae: 242.3207 - mse: 95719.9375 - val_loss: 276.0361 - val_mae: 276.0361 - val_mse: 105450.5234 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 242.5842 - mae: 242.5842 - mse: 96125.4609 - val_loss: 269.0769 - val_mae: 269.0769 - val_mse: 101640.3672 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 242.4017 - mae: 242.4017 - mse: 95402.3984 - val_loss: 259.7239 - val_mae: 259.7239 - val_mse: 96712.1172 - lr: 0.0010\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 239.3013 - mae: 239.3013 - mse: 94150.2812 - val_loss: 258.8670 - val_mae: 258.8670 - val_mse: 96215.7578 - lr: 0.0010\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 241.6668 - mae: 241.6668 - mse: 95488.6172 - val_loss: 270.4810 - val_mae: 270.4810 - val_mse: 102359.7500 - lr: 0.0010\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 238.9108 - mae: 238.9108 - mse: 93407.1484 - val_loss: 301.2780 - val_mae: 301.2780 - val_mse: 119849.7188 - lr: 0.0010\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 241.7026 - mae: 241.7026 - mse: 95460.7891 - val_loss: 245.5414 - val_mae: 245.5414 - val_mse: 89665.3125 - lr: 0.0010\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 236.2111 - mae: 236.2111 - mse: 92288.7734 - val_loss: 203.3958 - val_mae: 203.3958 - val_mse: 70965.7500 - lr: 0.0010\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 241.0490 - mae: 241.0490 - mse: 92944.4062 - val_loss: 224.3607 - val_mae: 224.3607 - val_mse: 79868.5547 - lr: 0.0010\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 240.3631 - mae: 240.3631 - mse: 93675.7500 - val_loss: 294.2998 - val_mae: 294.2998 - val_mse: 115866.9766 - lr: 0.0010\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 240.6264 - mae: 240.6264 - mse: 95026.9531 - val_loss: 253.6669 - val_mae: 253.6669 - val_mse: 93838.2266 - lr: 0.0010\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 237.7022 - mae: 237.7022 - mse: 92122.2969 - val_loss: 213.2701 - val_mae: 213.2701 - val_mse: 75207.1328 - lr: 0.0010\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 235.7757 - mae: 235.7757 - mse: 90857.7578 - val_loss: 248.8437 - val_mae: 248.8437 - val_mse: 91440.7266 - lr: 0.0010\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 235.6282 - mae: 235.6282 - mse: 91789.9609 - val_loss: 293.0933 - val_mae: 293.0933 - val_mse: 115207.1250 - lr: 0.0010\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 243.4503 - mae: 243.4503 - mse: 94395.4922 - val_loss: 218.3998 - val_mae: 218.3998 - val_mse: 77257.8359 - lr: 0.0010\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 246.5311 - mae: 246.5311 - mse: 97858.4219 - val_loss: 168.4419 - val_mae: 168.4419 - val_mse: 58223.6602 - lr: 0.0010\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 234.4766 - mae: 234.4766 - mse: 90462.0078 - val_loss: 298.2965 - val_mae: 298.2965 - val_mse: 118246.0625 - lr: 0.0010\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 242.1386 - mae: 242.1386 - mse: 93527.7578 - val_loss: 335.3438 - val_mae: 335.3438 - val_mse: 141561.2031 - lr: 0.0010\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 243.6396 - mae: 243.6396 - mse: 94982.9297 - val_loss: 216.4417 - val_mae: 216.4417 - val_mse: 76509.9375 - lr: 0.0010\n",
      "Epoch 74/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 232.7063 - mae: 232.7063 - mse: 87036.4609 - val_loss: 134.1606 - val_mae: 134.1606 - val_mse: 45135.7188 - lr: 0.0010\n",
      "Epoch 75/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 244.2251 - mae: 244.2251 - mse: 94834.6016 - val_loss: 197.6132 - val_mae: 197.6132 - val_mse: 68562.9609 - lr: 0.0010\n",
      "Epoch 76/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 229.5077 - mae: 229.5077 - mse: 85851.2812 - val_loss: 307.0216 - val_mae: 307.0216 - val_mse: 123179.9375 - lr: 0.0010\n",
      "Epoch 77/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 254.5286 - mae: 254.5286 - mse: 101795.2109 - val_loss: 294.5833 - val_mae: 294.5833 - val_mse: 115959.0312 - lr: 0.0010\n",
      "Epoch 78/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 238.8241 - mae: 238.8241 - mse: 90537.4219 - val_loss: 126.9699 - val_mae: 126.9699 - val_mse: 41624.8281 - lr: 0.0010\n",
      "Epoch 79/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 250.6191 - mae: 250.6191 - mse: 98859.4766 - val_loss: 148.1888 - val_mae: 148.1888 - val_mse: 50336.3320 - lr: 0.0010\n",
      "Epoch 80/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 232.8043 - mae: 232.8043 - mse: 88396.9609 - val_loss: 294.1772 - val_mae: 294.1772 - val_mse: 115336.4688 - lr: 0.0010\n",
      "Epoch 81/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 238.6830 - mae: 238.6830 - mse: 91090.7578 - val_loss: 315.2409 - val_mae: 315.2409 - val_mse: 128001.8359 - lr: 0.0010\n",
      "Epoch 82/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 243.5474 - mae: 243.5474 - mse: 94734.0625 - val_loss: 236.9097 - val_mae: 236.9097 - val_mse: 84996.3672 - lr: 0.0010\n",
      "Epoch 83/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 229.7390 - mae: 229.7390 - mse: 85687.4922 - val_loss: 201.9730 - val_mae: 201.9730 - val_mse: 69778.4922 - lr: 0.0010\n",
      "Epoch 84/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 232.6566 - mae: 232.6566 - mse: 86578.4375 - val_loss: 188.6776 - val_mae: 188.6776 - val_mse: 64605.4727 - lr: 0.0010\n",
      "Epoch 85/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 29ms/step - loss: 229.5685 - mae: 229.5685 - mse: 84792.2812 - val_loss: 226.3483 - val_mae: 226.3483 - val_mse: 80064.7734 - lr: 0.0010\n",
      "Epoch 86/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 229.2029 - mae: 229.2029 - mse: 84431.5625 - val_loss: 248.3190 - val_mae: 248.3190 - val_mse: 90396.0000 - lr: 0.0010\n",
      "Epoch 87/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 230.3970 - mae: 230.3970 - mse: 85310.0781 - val_loss: 255.3344 - val_mae: 255.3344 - val_mse: 93918.2109 - lr: 0.0010\n",
      "Epoch 88/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 230.5290 - mae: 230.5290 - mse: 85633.5469 - val_loss: 234.0661 - val_mae: 234.0661 - val_mse: 83620.2344 - lr: 0.0010\n",
      "Epoch 89/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 227.2812 - mae: 227.2812 - mse: 82623.2891 - val_loss: 164.3902 - val_mae: 164.3902 - val_mse: 56117.0000 - lr: 0.0010\n",
      "Epoch 90/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 229.7465 - mae: 229.7465 - mse: 84495.9609 - val_loss: 137.5071 - val_mae: 137.5071 - val_mse: 46143.3008 - lr: 0.0010\n",
      "Epoch 91/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 232.8570 - mae: 232.8570 - mse: 87053.1406 - val_loss: 219.9045 - val_mae: 219.9045 - val_mse: 77266.0703 - lr: 0.0010\n",
      "Epoch 92/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 227.7061 - mae: 227.7061 - mse: 84887.6328 - val_loss: 271.9056 - val_mae: 271.9056 - val_mse: 102644.5078 - lr: 0.0010\n",
      "Epoch 93/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 229.8064 - mae: 229.8064 - mse: 86236.0703 - val_loss: 212.9073 - val_mae: 212.9073 - val_mse: 74298.8203 - lr: 0.0010\n",
      "Epoch 94/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 227.2101 - mae: 227.2101 - mse: 83378.9922 - val_loss: 165.3361 - val_mae: 165.3361 - val_mse: 56469.9336 - lr: 0.0010\n",
      "Epoch 95/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 229.9688 - mae: 229.9688 - mse: 84366.7891 - val_loss: 179.1532 - val_mae: 179.1532 - val_mse: 61100.4883 - lr: 0.0010\n",
      "Epoch 96/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 228.0484 - mae: 228.0484 - mse: 83164.4766 - val_loss: 243.4795 - val_mae: 243.4795 - val_mse: 87994.8984 - lr: 0.0010\n",
      "Epoch 97/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 227.1781 - mae: 227.1781 - mse: 82799.8750 - val_loss: 256.1119 - val_mae: 256.1119 - val_mse: 94218.5938 - lr: 0.0010\n",
      "Epoch 98/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 230.2955 - mae: 230.2955 - mse: 84898.5781 - val_loss: 206.9367 - val_mae: 206.9367 - val_mse: 71641.9453 - lr: 0.0010\n",
      "Epoch 99/1000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 242.0984 - mae: 242.0984 - mse: 90477.8438 - val_loss: 126.1188 - val_mae: 126.1188 - val_mse: 41380.7070 - lr: 0.0010\n",
      "Epoch 100/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 230.1906 - mae: 230.1906 - mse: 84928.3438 - val_loss: 221.4928 - val_mae: 221.4928 - val_mse: 77897.8672 - lr: 0.0010\n",
      "Epoch 101/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 226.6111 - mae: 226.6111 - mse: 84345.2734 - val_loss: 305.5333 - val_mae: 305.5333 - val_mse: 121954.5859 - lr: 0.0010\n",
      "Epoch 102/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 234.9850 - mae: 234.9850 - mse: 88799.5000 - val_loss: 213.3765 - val_mae: 213.3765 - val_mse: 74581.6562 - lr: 0.0010\n",
      "Epoch 103/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 224.8924 - mae: 224.8924 - mse: 81158.2656 - val_loss: 117.2820 - val_mae: 117.2820 - val_mse: 36485.5508 - lr: 0.0010\n",
      "Epoch 104/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 239.1508 - mae: 239.1508 - mse: 90060.4375 - val_loss: 124.3680 - val_mae: 124.3680 - val_mse: 40490.6445 - lr: 0.0010\n",
      "Epoch 105/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 231.3674 - mae: 231.3674 - mse: 86330.5625 - val_loss: 208.5036 - val_mae: 208.5036 - val_mse: 72643.6016 - lr: 0.0010\n",
      "Epoch 106/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 227.6729 - mae: 227.6729 - mse: 83513.0781 - val_loss: 270.5428 - val_mae: 270.5428 - val_mse: 102044.3750 - lr: 0.0010\n",
      "Epoch 107/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 228.1100 - mae: 228.1100 - mse: 83118.3594 - val_loss: 201.8619 - val_mae: 201.8619 - val_mse: 69762.0234 - lr: 0.0010\n",
      "Epoch 108/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 223.6570 - mae: 223.6570 - mse: 79435.2188 - val_loss: 148.3646 - val_mae: 148.3646 - val_mse: 50368.8398 - lr: 0.0010\n",
      "Epoch 109/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 224.8621 - mae: 224.8621 - mse: 80758.6250 - val_loss: 145.4267 - val_mae: 145.4267 - val_mse: 49366.9258 - lr: 0.0010\n",
      "Epoch 110/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 227.0393 - mae: 227.0393 - mse: 80764.8828 - val_loss: 165.0871 - val_mae: 165.0871 - val_mse: 56415.7148 - lr: 0.0010\n",
      "Epoch 111/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 223.7121 - mae: 223.7121 - mse: 78903.7188 - val_loss: 150.3862 - val_mae: 150.3862 - val_mse: 50966.2500 - lr: 0.0010\n",
      "Epoch 112/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 224.6579 - mae: 224.6579 - mse: 80319.0469 - val_loss: 144.1252 - val_mae: 144.1252 - val_mse: 48795.0195 - lr: 0.0010\n",
      "Epoch 113/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 224.9453 - mae: 224.9453 - mse: 80442.5781 - val_loss: 159.3171 - val_mae: 159.3171 - val_mse: 54221.1133 - lr: 0.0010\n",
      "Epoch 114/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 222.0130 - mae: 222.0130 - mse: 77974.4609 - val_loss: 210.6334 - val_mae: 210.6334 - val_mse: 73255.4453 - lr: 0.0010\n",
      "Epoch 115/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 221.5867 - mae: 221.5867 - mse: 77930.5859 - val_loss: 228.7428 - val_mae: 228.7428 - val_mse: 81066.5234 - lr: 0.0010\n",
      "Epoch 116/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 224.7070 - mae: 224.7070 - mse: 79763.4766 - val_loss: 219.3591 - val_mae: 219.3591 - val_mse: 76783.8828 - lr: 0.0010\n",
      "Epoch 117/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 222.0332 - mae: 222.0332 - mse: 78012.3828 - val_loss: 226.7429 - val_mae: 226.7429 - val_mse: 79959.7109 - lr: 0.0010\n",
      "Epoch 118/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 221.7112 - mae: 221.7112 - mse: 78258.0078 - val_loss: 208.6082 - val_mae: 208.6082 - val_mse: 72053.4219 - lr: 0.0010\n",
      "Epoch 119/1000\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 225.2573 - mae: 225.2573 - mse: 75033.1875\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 221.1821 - mae: 221.1821 - mse: 77153.5312 - val_loss: 173.5525 - val_mae: 173.5525 - val_mse: 58800.3008 - lr: 0.0010\n",
      "Epoch 120/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 220.5395 - mae: 220.5395 - mse: 76480.5703 - val_loss: 166.5201 - val_mae: 166.5201 - val_mse: 56435.3125 - lr: 1.0000e-04\n",
      "Epoch 121/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 221.0417 - mae: 221.0417 - mse: 76735.6016 - val_loss: 163.2613 - val_mae: 163.2613 - val_mse: 55375.0352 - lr: 1.0000e-04\n",
      "Epoch 122/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 220.2965 - mae: 220.2965 - mse: 76625.4375 - val_loss: 154.9713 - val_mae: 154.9713 - val_mse: 52281.7305 - lr: 1.0000e-04\n",
      "Epoch 123/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 220.8976 - mae: 220.8976 - mse: 77055.6562 - val_loss: 150.2239 - val_mae: 150.2239 - val_mse: 50586.2656 - lr: 1.0000e-04\n",
      "Epoch 124/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 221.2301 - mae: 221.2301 - mse: 77248.5469 - val_loss: 151.4854 - val_mae: 151.4854 - val_mse: 51033.4492 - lr: 1.0000e-04\n",
      "Epoch 125/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 220.8627 - mae: 220.8627 - mse: 76976.8984 - val_loss: 159.2959 - val_mae: 159.2959 - val_mse: 53889.0781 - lr: 1.0000e-04\n",
      "Epoch 126/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 27ms/step - loss: 220.5229 - mae: 220.5229 - mse: 76893.9375 - val_loss: 170.2319 - val_mae: 170.2319 - val_mse: 57676.3867 - lr: 1.0000e-04\n",
      "Epoch 127/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 219.9949 - mae: 219.9949 - mse: 76066.6953 - val_loss: 179.0902 - val_mae: 179.0902 - val_mse: 60735.4883 - lr: 1.0000e-04\n",
      "Epoch 128/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 220.0203 - mae: 220.0203 - mse: 75975.3281 - val_loss: 189.6987 - val_mae: 189.6987 - val_mse: 64607.3320 - lr: 1.0000e-04\n",
      "Epoch 129/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 219.9661 - mae: 219.9661 - mse: 76008.9375 - val_loss: 199.5429 - val_mae: 199.5429 - val_mse: 68397.6094 - lr: 1.0000e-04\n",
      "Epoch 130/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 219.8948 - mae: 219.8948 - mse: 76117.0938 - val_loss: 210.7256 - val_mae: 210.7256 - val_mse: 72945.7188 - lr: 1.0000e-04\n",
      "Epoch 131/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 220.7213 - mae: 220.7213 - mse: 76904.2031 - val_loss: 223.3224 - val_mae: 223.3224 - val_mse: 78373.4141 - lr: 1.0000e-04\n",
      "Epoch 132/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 221.2755 - mae: 221.2755 - mse: 77657.0078 - val_loss: 229.3333 - val_mae: 229.3333 - val_mse: 81077.3516 - lr: 1.0000e-04\n",
      "Epoch 133/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 221.1980 - mae: 221.1980 - mse: 77776.9062 - val_loss: 228.1438 - val_mae: 228.1438 - val_mse: 80555.8203 - lr: 1.0000e-04\n",
      "Epoch 134/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 220.8954 - mae: 220.8954 - mse: 77541.0312 - val_loss: 220.8974 - val_mae: 220.8974 - val_mse: 77343.6406 - lr: 1.0000e-04\n",
      "Epoch 135/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 220.5011 - mae: 220.5011 - mse: 77109.5391 - val_loss: 210.9557 - val_mae: 210.9557 - val_mse: 73098.8438 - lr: 1.0000e-04\n",
      "Epoch 136/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 219.9916 - mae: 219.9916 - mse: 76384.0469 - val_loss: 194.7340 - val_mae: 194.7340 - val_mse: 66586.7109 - lr: 1.0000e-04\n",
      "Epoch 137/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 220.2907 - mae: 220.2907 - mse: 76178.3672 - val_loss: 179.1248 - val_mae: 179.1248 - val_mse: 60813.0781 - lr: 1.0000e-04\n",
      "Epoch 138/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 220.4962 - mae: 220.4962 - mse: 76135.7344 - val_loss: 167.9414 - val_mae: 167.9414 - val_mse: 56972.8906 - lr: 1.0000e-04\n",
      "Epoch 139/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 219.8365 - mae: 219.8365 - mse: 75976.7500 - val_loss: 162.7542 - val_mae: 162.7542 - val_mse: 55258.4531 - lr: 1.0000e-04\n",
      "Epoch 140/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 220.0917 - mae: 220.0917 - mse: 76067.8438 - val_loss: 161.3306 - val_mae: 161.3306 - val_mse: 54704.1914 - lr: 1.0000e-04\n",
      "Epoch 141/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 220.0155 - mae: 220.0155 - mse: 76103.4375 - val_loss: 158.8376 - val_mae: 158.8376 - val_mse: 53748.9648 - lr: 1.0000e-04\n",
      "Epoch 142/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 220.0866 - mae: 220.0866 - mse: 76205.6719 - val_loss: 158.6656 - val_mae: 158.6656 - val_mse: 53674.4023 - lr: 1.0000e-04\n",
      "Epoch 143/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 220.1590 - mae: 220.1590 - mse: 76221.3438 - val_loss: 160.6295 - val_mae: 160.6295 - val_mse: 54400.7539 - lr: 1.0000e-04\n",
      "Epoch 144/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 220.4900 - mae: 220.4900 - mse: 76434.3516 - val_loss: 162.7603 - val_mae: 162.7603 - val_mse: 55201.6992 - lr: 1.0000e-04\n",
      "Epoch 145/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 219.8232 - mae: 219.8232 - mse: 75965.6797 - val_loss: 161.3037 - val_mae: 161.3037 - val_mse: 54631.1133 - lr: 1.0000e-04\n",
      "Epoch 146/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 220.0261 - mae: 220.0261 - mse: 76121.5469 - val_loss: 161.6505 - val_mae: 161.6505 - val_mse: 54754.3711 - lr: 1.0000e-04\n",
      "Epoch 147/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 220.6383 - mae: 220.6383 - mse: 76263.4766 - val_loss: 168.8262 - val_mae: 168.8262 - val_mse: 57149.0469 - lr: 1.0000e-04\n",
      "Epoch 148/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 219.5670 - mae: 219.5670 - mse: 75737.2734 - val_loss: 168.4277 - val_mae: 168.4277 - val_mse: 57004.7969 - lr: 1.0000e-04\n",
      "Epoch 149/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 219.5813 - mae: 219.5813 - mse: 75715.0312 - val_loss: 167.9185 - val_mae: 167.9185 - val_mse: 56828.0430 - lr: 1.0000e-04\n",
      "Epoch 150/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 219.6012 - mae: 219.6012 - mse: 75761.0625 - val_loss: 165.4070 - val_mae: 165.4070 - val_mse: 55994.6367 - lr: 1.0000e-04\n",
      "Epoch 151/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 219.9035 - mae: 219.9035 - mse: 75832.2188 - val_loss: 161.4053 - val_mae: 161.4053 - val_mse: 54627.4180 - lr: 1.0000e-04\n",
      "Epoch 152/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 219.6688 - mae: 219.6688 - mse: 75840.0312 - val_loss: 164.1578 - val_mae: 164.1578 - val_mse: 55575.3320 - lr: 1.0000e-04\n",
      "Epoch 153/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 219.5571 - mae: 219.5571 - mse: 75733.4219 - val_loss: 168.6484 - val_mae: 168.6484 - val_mse: 57053.2305 - lr: 1.0000e-04\n",
      "Epoch 154/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 219.4035 - mae: 219.4035 - mse: 75625.8516 - val_loss: 169.9092 - val_mae: 169.9092 - val_mse: 57483.0273 - lr: 1.0000e-04\n",
      "Epoch 155/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 219.4501 - mae: 219.4501 - mse: 75657.7578 - val_loss: 170.8142 - val_mae: 170.8142 - val_mse: 57797.9375 - lr: 1.0000e-04\n",
      "Epoch 156/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 219.4829 - mae: 219.4829 - mse: 75560.3438 - val_loss: 169.3739 - val_mae: 169.3739 - val_mse: 57326.0938 - lr: 1.0000e-04\n",
      "Epoch 157/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 219.3007 - mae: 219.3007 - mse: 75511.6016 - val_loss: 164.1024 - val_mae: 164.1024 - val_mse: 55594.4023 - lr: 1.0000e-04\n",
      "Epoch 158/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 219.5783 - mae: 219.5783 - mse: 75758.1719 - val_loss: 158.4892 - val_mae: 158.4892 - val_mse: 53552.1680 - lr: 1.0000e-04\n",
      "Epoch 159/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 219.6145 - mae: 219.6145 - mse: 75790.1484 - val_loss: 157.8324 - val_mae: 157.8324 - val_mse: 53307.5664 - lr: 1.0000e-04\n",
      "Epoch 160/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 219.6167 - mae: 219.6167 - mse: 75758.7188 - val_loss: 159.2557 - val_mae: 159.2557 - val_mse: 53842.0508 - lr: 1.0000e-04\n",
      "Epoch 161/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 219.7377 - mae: 219.7377 - mse: 75840.4062 - val_loss: 162.0586 - val_mae: 162.0586 - val_mse: 54908.6758 - lr: 1.0000e-04\n",
      "Epoch 162/1000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 219.1260 - mae: 219.1260 - mse: 75413.6484 - val_loss: 173.2223 - val_mae: 173.2223 - val_mse: 58638.9648 - lr: 1.0000e-04\n",
      "Epoch 163/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 219.8845 - mae: 219.8845 - mse: 75894.5469 - val_loss: 186.6998 - val_mae: 186.6998 - val_mse: 63423.5820 - lr: 1.0000e-04\n",
      "Epoch 164/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 219.0992 - mae: 219.0992 - mse: 75238.8672 - val_loss: 192.8736 - val_mae: 192.8736 - val_mse: 65733.8984 - lr: 1.0000e-04\n",
      "Epoch 165/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 219.3590 - mae: 219.3590 - mse: 75506.4375 - val_loss: 199.9812 - val_mae: 199.9812 - val_mse: 68500.0391 - lr: 1.0000e-04\n",
      "Epoch 166/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 219.1752 - mae: 219.1752 - mse: 75669.2734 - val_loss: 203.2848 - val_mae: 203.2848 - val_mse: 69822.4844 - lr: 1.0000e-04\n",
      "Epoch 167/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 28ms/step - loss: 219.2518 - mae: 219.2518 - mse: 75737.0781 - val_loss: 203.2083 - val_mae: 203.2083 - val_mse: 69812.2188 - lr: 1.0000e-04\n",
      "Epoch 168/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 219.1161 - mae: 219.1161 - mse: 75633.4609 - val_loss: 198.2709 - val_mae: 198.2709 - val_mse: 67867.6328 - lr: 1.0000e-04\n",
      "Epoch 169/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 218.9837 - mae: 218.9837 - mse: 75444.1016 - val_loss: 192.0581 - val_mae: 192.0581 - val_mse: 65477.2070 - lr: 1.0000e-04\n",
      "Epoch 170/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 219.0130 - mae: 219.0130 - mse: 75365.3516 - val_loss: 184.5970 - val_mae: 184.5970 - val_mse: 62705.1211 - lr: 1.0000e-04\n",
      "Epoch 171/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 219.3523 - mae: 219.3523 - mse: 75234.5938 - val_loss: 178.1090 - val_mae: 178.1090 - val_mse: 60382.6562 - lr: 1.0000e-04\n",
      "Epoch 172/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 218.9684 - mae: 218.9684 - mse: 75097.7188 - val_loss: 176.6974 - val_mae: 176.6974 - val_mse: 59888.3398 - lr: 1.0000e-04\n",
      "Epoch 173/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 218.9048 - mae: 218.9048 - mse: 75039.7969 - val_loss: 177.2555 - val_mae: 177.2555 - val_mse: 60088.0000 - lr: 1.0000e-04\n",
      "Epoch 174/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 218.9618 - mae: 218.9618 - mse: 75153.9688 - val_loss: 179.7534 - val_mae: 179.7534 - val_mse: 60973.8281 - lr: 1.0000e-04\n",
      "Epoch 175/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 219.0063 - mae: 219.0063 - mse: 75191.4062 - val_loss: 179.4113 - val_mae: 179.4113 - val_mse: 60853.4336 - lr: 1.0000e-04\n",
      "Epoch 176/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 218.8091 - mae: 218.8091 - mse: 74994.6250 - val_loss: 174.6720 - val_mae: 174.6720 - val_mse: 59192.2656 - lr: 1.0000e-04\n",
      "Epoch 177/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 218.9521 - mae: 218.9521 - mse: 75007.8828 - val_loss: 166.1904 - val_mae: 166.1904 - val_mse: 56325.5938 - lr: 1.0000e-04\n",
      "Epoch 178/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 218.7794 - mae: 218.7794 - mse: 75052.0312 - val_loss: 164.2542 - val_mae: 164.2542 - val_mse: 55684.7227 - lr: 1.0000e-04\n",
      "Epoch 179/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 219.0659 - mae: 219.0659 - mse: 75275.7031 - val_loss: 162.6836 - val_mae: 162.6836 - val_mse: 55165.5938 - lr: 1.0000e-04\n",
      "Epoch 180/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 218.7794 - mae: 218.7794 - mse: 75038.3594 - val_loss: 168.3874 - val_mae: 168.3874 - val_mse: 57022.2188 - lr: 1.0000e-04\n",
      "Epoch 181/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 218.5326 - mae: 218.5326 - mse: 74916.3984 - val_loss: 174.8912 - val_mae: 174.8912 - val_mse: 59211.3438 - lr: 1.0000e-04\n",
      "Epoch 182/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 218.7800 - mae: 218.7800 - mse: 74859.9766 - val_loss: 182.2157 - val_mae: 182.2157 - val_mse: 61775.9883 - lr: 1.0000e-04\n",
      "Epoch 183/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 219.3022 - mae: 219.3022 - mse: 75368.4062 - val_loss: 186.2363 - val_mae: 186.2363 - val_mse: 63228.5352 - lr: 1.0000e-04\n",
      "Epoch 184/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 218.5462 - mae: 218.5462 - mse: 74863.0547 - val_loss: 182.4579 - val_mae: 182.4579 - val_mse: 61846.3438 - lr: 1.0000e-04\n",
      "Epoch 185/1000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 218.4407 - mae: 218.4407 - mse: 74706.3594 - val_loss: 177.0360 - val_mae: 177.0360 - val_mse: 59916.2383 - lr: 1.0000e-04\n",
      "Epoch 186/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 219.2620 - mae: 219.2620 - mse: 74904.7109 - val_loss: 169.5003 - val_mae: 169.5003 - val_mse: 57331.4570 - lr: 1.0000e-04\n",
      "Epoch 187/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 218.3311 - mae: 218.3311 - mse: 74777.0938 - val_loss: 170.0771 - val_mae: 170.0771 - val_mse: 57532.9102 - lr: 1.0000e-04\n",
      "Epoch 188/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 218.4966 - mae: 218.4966 - mse: 74910.8828 - val_loss: 167.5408 - val_mae: 167.5408 - val_mse: 56701.1055 - lr: 1.0000e-04\n",
      "Epoch 189/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 218.1707 - mae: 218.1707 - mse: 74781.2188 - val_loss: 169.7648 - val_mae: 169.7648 - val_mse: 57455.1250 - lr: 1.0000e-04\n",
      "Epoch 190/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 218.1927 - mae: 218.1927 - mse: 74781.6328 - val_loss: 171.1070 - val_mae: 171.1070 - val_mse: 57914.1992 - lr: 1.0000e-04\n",
      "Epoch 191/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 218.3436 - mae: 218.3436 - mse: 74828.2734 - val_loss: 171.3697 - val_mae: 171.3697 - val_mse: 58006.0820 - lr: 1.0000e-04\n",
      "Epoch 192/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 218.2598 - mae: 218.2598 - mse: 74742.9219 - val_loss: 176.0814 - val_mae: 176.0814 - val_mse: 59629.7383 - lr: 1.0000e-04\n",
      "Epoch 193/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 218.1547 - mae: 218.1547 - mse: 74691.8984 - val_loss: 177.4071 - val_mae: 177.4071 - val_mse: 60096.0195 - lr: 1.0000e-04\n",
      "Epoch 194/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 218.0256 - mae: 218.0256 - mse: 74591.6172 - val_loss: 175.6829 - val_mae: 175.6829 - val_mse: 59494.6445 - lr: 1.0000e-04\n",
      "Epoch 195/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 217.9967 - mae: 217.9967 - mse: 74548.4219 - val_loss: 174.0430 - val_mae: 174.0430 - val_mse: 58928.5000 - lr: 1.0000e-04\n",
      "Epoch 196/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 217.9920 - mae: 217.9920 - mse: 74541.2266 - val_loss: 172.5347 - val_mae: 172.5347 - val_mse: 58411.9258 - lr: 1.0000e-04\n",
      "Epoch 197/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 217.9088 - mae: 217.9088 - mse: 74510.5078 - val_loss: 168.9078 - val_mae: 168.9078 - val_mse: 57188.0977 - lr: 1.0000e-04\n",
      "Epoch 198/1000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 217.9079 - mae: 217.9079 - mse: 74565.3594 - val_loss: 163.9045 - val_mae: 163.9045 - val_mse: 55540.0664 - lr: 1.0000e-04\n",
      "Epoch 199/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 218.4716 - mae: 218.4716 - mse: 75037.5781 - val_loss: 158.0731 - val_mae: 158.0731 - val_mse: 53414.6680 - lr: 1.0000e-04\n",
      "Epoch 200/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 218.6238 - mae: 218.6238 - mse: 75064.3828 - val_loss: 159.2157 - val_mae: 159.2157 - val_mse: 53843.3867 - lr: 1.0000e-04\n",
      "Epoch 201/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 218.0187 - mae: 218.0187 - mse: 74634.2969 - val_loss: 168.8875 - val_mae: 168.8875 - val_mse: 57170.6680 - lr: 1.0000e-04\n",
      "Epoch 202/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 218.1223 - mae: 218.1223 - mse: 74510.7500 - val_loss: 184.3595 - val_mae: 184.3595 - val_mse: 62567.9336 - lr: 1.0000e-04\n",
      "Epoch 203/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 218.0131 - mae: 218.0131 - mse: 74630.7188 - val_loss: 194.2813 - val_mae: 194.2813 - val_mse: 66273.1172 - lr: 1.0000e-04\n",
      "Epoch 204/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 217.6837 - mae: 217.6837 - mse: 74606.4062 - val_loss: 199.4110 - val_mae: 199.4110 - val_mse: 68271.9609 - lr: 1.0000e-04\n",
      "Epoch 205/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 217.7444 - mae: 217.7444 - mse: 74752.3594 - val_loss: 202.5206 - val_mae: 202.5206 - val_mse: 69521.0234 - lr: 1.0000e-04\n",
      "Epoch 206/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 217.9573 - mae: 217.9573 - mse: 74972.1406 - val_loss: 204.8126 - val_mae: 204.8126 - val_mse: 70462.3516 - lr: 1.0000e-04\n",
      "Epoch 207/1000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 217.9247 - mae: 217.9247 - mse: 74977.9062 - val_loss: 201.3123 - val_mae: 201.3123 - val_mse: 69081.2109 - lr: 1.0000e-04\n",
      "Epoch 208/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 28ms/step - loss: 217.6738 - mae: 217.6738 - mse: 74716.2031 - val_loss: 195.7524 - val_mae: 195.7524 - val_mse: 66908.8359 - lr: 1.0000e-04\n",
      "Epoch 209/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 217.4043 - mae: 217.4043 - mse: 74492.8984 - val_loss: 188.9634 - val_mae: 188.9634 - val_mse: 64329.9805 - lr: 1.0000e-04\n",
      "Epoch 210/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 217.3029 - mae: 217.3029 - mse: 74092.4766 - val_loss: 181.0332 - val_mae: 181.0332 - val_mse: 61427.1445 - lr: 1.0000e-04\n",
      "Epoch 211/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 217.1665 - mae: 217.1665 - mse: 73985.3516 - val_loss: 172.3027 - val_mae: 172.3027 - val_mse: 58373.6836 - lr: 1.0000e-04\n",
      "Epoch 212/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 217.5124 - mae: 217.5124 - mse: 74338.5781 - val_loss: 160.1774 - val_mae: 160.1774 - val_mse: 54244.9414 - lr: 1.0000e-04\n",
      "Epoch 213/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 219.4463 - mae: 219.4463 - mse: 75225.4375 - val_loss: 157.3685 - val_mae: 157.3685 - val_mse: 53193.9414 - lr: 1.0000e-04\n",
      "Epoch 214/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 217.1578 - mae: 217.1578 - mse: 74139.6562 - val_loss: 170.7226 - val_mae: 170.7226 - val_mse: 57844.3320 - lr: 1.0000e-04\n",
      "Epoch 215/1000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 216.7516 - mae: 216.7516 - mse: 73641.1484 - val_loss: 186.6305 - val_mae: 186.6305 - val_mse: 63481.6562 - lr: 1.0000e-04\n",
      "Epoch 216/1000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 217.0340 - mae: 217.0340 - mse: 74132.5781 - val_loss: 201.5261 - val_mae: 201.5261 - val_mse: 69222.7031 - lr: 1.0000e-04\n",
      "Epoch 217/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 217.7091 - mae: 217.7091 - mse: 74531.0938 - val_loss: 210.9676 - val_mae: 210.9676 - val_mse: 73080.3047 - lr: 1.0000e-04\n",
      "Epoch 218/1000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 217.4993 - mae: 217.4993 - mse: 74923.2422 - val_loss: 210.6984 - val_mae: 210.6984 - val_mse: 72973.2266 - lr: 1.0000e-04\n",
      "Epoch 219/1000\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 217.2475 - mae: 217.2475 - mse: 81738.2812\n",
      "Epoch 00219: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 218.2247 - mae: 218.2247 - mse: 75376.2500 - val_loss: 210.5861 - val_mae: 210.5861 - val_mse: 72949.0000 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mae\",optimizer = tf.keras.optimizers.Adam(), metrics=[\"mae\",\"mse\"])\n",
    "history = model.fit(final_x_zeros[:50],final_y_zeros[:50],\n",
    "                    epochs = 1000,\n",
    "                    validation_data = (final_x_zeros[50:], final_y_zeros[50:]),\n",
    "                   callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", \n",
    "                                                        patience=200, \n",
    "                                                        restore_best_weights=True),\n",
    "                      tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", \n",
    "                                                           patience=100, \n",
    "                                                           verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97b89833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step - loss: 113.8574 - mae: 113.8574 - mse: 27533.9824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[113.857421875, 113.857421875, 27533.982421875]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(final_x_zeros[50:],final_y_zeros[50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf45e4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: conv1d_maruti suzuki\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"conv1d_maruti suzuki\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ws_env",
   "language": "python",
   "name": "ws_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
