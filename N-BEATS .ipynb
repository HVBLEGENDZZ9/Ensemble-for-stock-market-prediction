{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6951d219",
   "metadata": {},
   "source": [
    "# GETTING AND PREPARING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58049079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "df_stock = pd.read_csv(\"maruti_suzuki/MARUTI.NS.csv\",\n",
    "                 parse_dates = [\"Date\"],\n",
    "                 index_col = [\"Date\"])\n",
    "df_posts = pd.read_excel(\"maruti_suzuki/maruti_suzuki_final_posts.xlsx\")\n",
    "# removing the unnecessary columns\n",
    "df_posts.drop([\"Unnamed: 0\"], axis=1,inplace=True)\n",
    "# removing spam posts\n",
    "df_posts = df_posts[df_posts.Spam==0.0]\n",
    "df_posts.drop([\"Spam\"],axis=1,inplace=True)\n",
    "# sliding a window of 7 days and adding all the TIs\n",
    "from stock_helper import prepare_data\n",
    "x,y = prepare_data(df_stock)\n",
    "final_x = x[np.datetime64(\"2021-11-13\"):]\n",
    "final_y = y[np.datetime64(\"2021-11-13\"):]\n",
    "# reversing the posts data\n",
    "df_posts = df_posts[::-1]\n",
    "final_posts = df_posts[7:]\n",
    "# loading the sentiment analysis model\n",
    "sent_model = tf.keras.models.load_model(\"final_bert\")\n",
    "# removing duplicates from the data\n",
    "final_posts.drop_duplicates(subset=['Messages'])\n",
    "# calculating the sentiments score\n",
    "sentiments = []\n",
    "prev = np.datetime64(\"2015-11-12 21:31:26\")\n",
    "for i in final_y.index:\n",
    "    total=0\n",
    "    cnt=0\n",
    "    for j in final_posts.itertuples():\n",
    "        _,msg,time = j\n",
    "        if np.datetime64(time)<np.datetime64(i) and np.datetime64(time)>prev:\n",
    "            total += tf.squeeze(sent_model.predict([msg])).numpy()\n",
    "            cnt+=1\n",
    "    prev = np.datetime64(i)\n",
    "    if(cnt==0):\n",
    "        sentiments.append(0)\n",
    "    else:\n",
    "        sentiments.append(total/cnt)\n",
    "# getting indices where sentiments score is 0\n",
    "zero_index = []\n",
    "for i,j in enumerate(sentiments):\n",
    "    if(j==0):\n",
    "        zero_index.append(i)\n",
    "# removing all the zero values indices\n",
    "sentiments = np.delete(sentiments,zero_index)\n",
    "final_x_zeros = final_x.copy()\n",
    "final_y_zeros = final_y.copy()\n",
    "final_y_zeros = final_y_zeros.to_frame()\n",
    "final_x_zeros['removal_assist'] = np.arange(0,len(final_x),1)\n",
    "final_y_zeros['removal_assist'] = np.arange(0,len(final_x),1)\n",
    "final_y_zeros = final_y_zeros[final_y_zeros.removal_assist.isin(zero_index)==False]\n",
    "final_x_zeros = final_x_zeros[final_x_zeros.removal_assist.isin(zero_index)==False]\n",
    "# removing the added helper column\n",
    "final_x_zeros.drop([\"removal_assist\"], axis=1,inplace=True)\n",
    "final_y_zeros.drop([\"removal_assist\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7de90b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = int(np.round(len(final_x_zeros)*0.8))\n",
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a66168",
   "metadata": {},
   "source": [
    "# BUILDING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed6a1514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 7), dtype=float32, numpy=\n",
       " array([[ 0.32581076, -0.11805074,  0.12559159, -0.12523536,  0.02738374,\n",
       "         -0.07395406,  0.14072429]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.38247153]], dtype=float32)>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#building the blocks\n",
    "class blocks(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 number_neurons:int,\n",
    "                 number_layers:int,\n",
    "                 window_size:int,\n",
    "                 horizon_size:int,\n",
    "                 theta_size:int,\n",
    "                 **kwargs): #**kwargs takes care of the arguements of the parent class(input_size)\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden_neurons = number_neurons\n",
    "        self.hidden_layers = number_layers\n",
    "        self.output_size = horizon_size\n",
    "        self.input_size = window_size\n",
    "        self.theta_size = theta_size\n",
    "        \n",
    "        self.fc_layers = [tf.keras.layers.Dense(self.hidden_neurons, activation = \"relu\") for _ in range(self.hidden_layers)]\n",
    "        self.theta_layer = tf.keras.layers.Dense(self.theta_size, name = \"theta\")\n",
    "    def call(self, inputs):\n",
    "        x = inputs \n",
    "        for i in self.fc_layers:\n",
    "            x = i(x)\n",
    "        outputs = self.theta_layer(x)\n",
    "        backcasts, forecasts = outputs[:,:self.input_size], outputs[:,-int(self.output_size):]\n",
    "        return backcasts, forecasts\n",
    "# testing the block layer\n",
    "trial_data = tf.expand_dims(tf.range(7),axis=0).numpy()\n",
    "block = blocks(number_neurons = 512,\n",
    "                 number_layers = 4,\n",
    "                 window_size = 7,\n",
    "                 horizon_size = 1,\n",
    "                 theta_size = 8, # theta_size = window_size(backcast) + horizon_size(forecast)\n",
    "              )\n",
    "backcasts, forecasts = block(trial_data)\n",
    "backcasts, forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74d5ee0",
   "metadata": {},
   "source": [
    "# BUILDING, COMPILING AND FITTING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c198623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the hyper parameters\n",
    "number_neurons = 512\n",
    "number_layers = 4\n",
    "epochs = 5000\n",
    "number_stacks = 30\n",
    "input_size = 71\n",
    "output_size = 1\n",
    "theta_size = 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8dc384a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "2/2 [==============================] - 6s 1s/step - loss: 137669.6250 - mae: 137669.6250 - mse: 46847045632.0000 - val_loss: 68247.0859 - val_mae: 68247.0859 - val_mse: 4659890688.0000 - lr: 0.0010\n",
      "Epoch 2/5000\n",
      "2/2 [==============================] - 0s 264ms/step - loss: 42405.3516 - mae: 42405.3516 - mse: 2552830976.0000 - val_loss: 28412.8691 - val_mae: 28412.8691 - val_mse: 807964928.0000 - lr: 0.0010\n",
      "Epoch 3/5000\n",
      "2/2 [==============================] - 0s 230ms/step - loss: 24994.5547 - mae: 24994.5547 - mse: 630059840.0000 - val_loss: 3130.4424 - val_mae: 3130.4424 - val_mse: 9847427.0000 - lr: 0.0010\n",
      "Epoch 4/5000\n",
      "2/2 [==============================] - 0s 221ms/step - loss: 7766.5337 - mae: 7766.5337 - mse: 97890752.0000 - val_loss: 175.2641 - val_mae: 175.2641 - val_mse: 51506.6562 - lr: 0.0010\n",
      "Epoch 5/5000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 632.8467 - mae: 632.8466 - mse: 585771.0000 - val_loss: 14881.7656 - val_mae: 14881.7656 - val_mse: 221633920.0000 - lr: 0.0010\n",
      "Epoch 6/5000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 10383.2617 - mae: 10383.2617 - mse: 134660416.0000 - val_loss: 9518.1396 - val_mae: 9518.1396 - val_mse: 90618264.0000 - lr: 0.0010\n",
      "Epoch 7/5000\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 6604.7876 - mae: 6604.7876 - mse: 49269524.0000 - val_loss: 2412.0945 - val_mae: 2412.0945 - val_mse: 5878034.0000 - lr: 0.0010\n",
      "Epoch 8/5000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1849.8545 - mae: 1849.8545 - mse: 4836129.5000 - val_loss: 4077.4417 - val_mae: 4077.4417 - val_mse: 16653016.0000 - lr: 0.0010\n",
      "Epoch 9/5000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 2446.3474 - mae: 2446.3474 - mse: 8221972.5000 - val_loss: 4356.1157 - val_mae: 4356.1157 - val_mse: 19066984.0000 - lr: 0.0010\n",
      "Epoch 10/5000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 3377.1228 - mae: 3377.1228 - mse: 13317946.0000 - val_loss: 4204.2212 - val_mae: 4204.2212 - val_mse: 17698378.0000 - lr: 0.0010\n",
      "Epoch 11/5000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 2921.3708 - mae: 2921.3708 - mse: 9429503.0000 - val_loss: 2923.2959 - val_mae: 2923.2959 - val_mse: 8603719.0000 - lr: 0.0010\n",
      "Epoch 12/5000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 2216.8176 - mae: 2216.8176 - mse: 5860258.0000 - val_loss: 5072.7988 - val_mae: 5072.7988 - val_mse: 25762330.0000 - lr: 0.0010\n",
      "Epoch 13/5000\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 3416.4712 - mae: 3416.4712 - mse: 12612125.0000 - val_loss: 665.5115 - val_mae: 665.5115 - val_mse: 486174.2500 - lr: 0.0010\n",
      "Epoch 14/5000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 731.1646 - mae: 731.1646 - mse: 734491.4375 - val_loss: 2243.9001 - val_mae: 2243.9001 - val_mse: 5063566.0000 - lr: 0.0010\n",
      "Epoch 15/5000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1357.6050 - mae: 1357.6050 - mse: 2316215.5000 - val_loss: 1307.6139 - val_mae: 1307.6139 - val_mse: 1743554.8750 - lr: 0.0010\n",
      "Epoch 16/5000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1020.8051 - mae: 1020.8051 - mse: 1133673.0000 - val_loss: 649.9879 - val_mae: 649.9879 - val_mse: 458771.5938 - lr: 0.0010\n",
      "Epoch 17/5000\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 532.2607 - mae: 532.2607 - mse: 398070.5938 - val_loss: 1238.0354 - val_mae: 1238.0354 - val_mse: 1563776.6250 - lr: 0.0010\n",
      "Epoch 18/5000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 634.9090 - mae: 634.9090 - mse: 567740.6875 - val_loss: 190.4624 - val_mae: 190.4624 - val_mse: 48532.6758 - lr: 0.0010\n",
      "Epoch 19/5000\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 534.5949 - mae: 534.5949 - mse: 388468.1250 - val_loss: 495.1394 - val_mae: 495.1394 - val_mse: 279061.1562 - lr: 0.0010\n",
      "Epoch 20/5000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 745.8611 - mae: 745.8611 - mse: 992882.9375 - val_loss: 924.5185 - val_mae: 924.5185 - val_mse: 893704.1875 - lr: 0.0010\n",
      "Epoch 21/5000\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 890.2234 - mae: 890.2234 - mse: 1019365.9375 - val_loss: 696.0161 - val_mae: 696.0161 - val_mse: 511008.4688 - lr: 0.0010\n",
      "Epoch 22/5000\n",
      "2/2 [==============================] - 0s 252ms/step - loss: 445.4926 - mae: 445.4926 - mse: 293952.9375 - val_loss: 134.7456 - val_mae: 134.7456 - val_mse: 41394.8750 - lr: 0.0010\n",
      "Epoch 23/5000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 313.5414 - mae: 313.5414 - mse: 127237.0000 - val_loss: 199.8130 - val_mae: 199.8130 - val_mse: 47677.4688 - lr: 0.0010\n",
      "Epoch 24/5000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 232.7229 - mae: 232.7229 - mse: 83688.1719 - val_loss: 361.0164 - val_mae: 361.0164 - val_mse: 159658.2344 - lr: 0.0010\n",
      "Epoch 25/5000\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 286.5582 - mae: 286.5582 - mse: 120596.7812 - val_loss: 405.0675 - val_mae: 405.0675 - val_mse: 192666.2500 - lr: 0.0010\n",
      "Epoch 26/5000\n",
      "2/2 [==============================] - 0s 230ms/step - loss: 187.3913 - mae: 187.3913 - mse: 60584.1094 - val_loss: 133.3232 - val_mae: 133.3232 - val_mse: 30364.3301 - lr: 0.0010\n",
      "Epoch 27/5000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 296.5849 - mae: 296.5849 - mse: 112187.1797 - val_loss: 135.7224 - val_mae: 135.7224 - val_mse: 46995.4844 - lr: 0.0010\n",
      "Epoch 28/5000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 175.8492 - mae: 175.8492 - mse: 50836.8242 - val_loss: 523.8550 - val_mae: 523.8550 - val_mse: 305202.2188 - lr: 0.0010\n",
      "Epoch 29/5000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 314.0721 - mae: 314.0721 - mse: 124029.4219 - val_loss: 238.2231 - val_mae: 238.2231 - val_mse: 88279.8516 - lr: 0.0010\n",
      "Epoch 30/5000\n",
      "2/2 [==============================] - 0s 254ms/step - loss: 226.2572 - mae: 226.2572 - mse: 94822.1172 - val_loss: 126.8589 - val_mae: 126.8589 - val_mse: 34391.2148 - lr: 0.0010\n",
      "Epoch 31/5000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 177.4584 - mae: 177.4584 - mse: 49010.1211 - val_loss: 502.6150 - val_mae: 502.6150 - val_mse: 282720.6562 - lr: 0.0010\n",
      "Epoch 32/5000\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 275.4449 - mae: 275.4449 - mse: 114933.4531 - val_loss: 509.0384 - val_mae: 509.0384 - val_mse: 292456.7188 - lr: 0.0010\n",
      "Epoch 33/5000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 467.1426 - mae: 467.1426 - mse: 252373.4531 - val_loss: 516.5814 - val_mae: 516.5814 - val_mse: 293975.8125 - lr: 0.0010\n",
      "Epoch 34/5000\n",
      "2/2 [==============================] - 0s 280ms/step - loss: 367.8747 - mae: 367.8747 - mse: 174501.2031 - val_loss: 118.6461 - val_mae: 118.6461 - val_mse: 32922.3086 - lr: 0.0010\n",
      "Epoch 35/5000\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 296.5052 - mae: 296.5052 - mse: 118893.5625 - val_loss: 206.0255 - val_mae: 206.0255 - val_mse: 73308.0547 - lr: 0.0010\n",
      "Epoch 36/5000\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 282.6255 - mae: 282.6255 - mse: 120750.7266 - val_loss: 478.1544 - val_mae: 478.1544 - val_mse: 257802.2500 - lr: 0.0010\n",
      "Epoch 37/5000\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 315.3912 - mae: 315.3912 - mse: 124922.0391 - val_loss: 200.4932 - val_mae: 200.4932 - val_mse: 47046.8555 - lr: 0.0010\n",
      "Epoch 38/5000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 341.8097 - mae: 341.8097 - mse: 152870.0000 - val_loss: 439.4684 - val_mae: 439.4684 - val_mse: 222360.7031 - lr: 0.0010\n",
      "Epoch 39/5000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 361.9695 - mae: 361.9695 - mse: 164083.2656 - val_loss: 372.6356 - val_mae: 372.6356 - val_mse: 155967.5156 - lr: 0.0010\n",
      "Epoch 40/5000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 370.2246 - mae: 370.2246 - mse: 184642.2969 - val_loss: 312.0095 - val_mae: 312.0095 - val_mse: 126881.1797 - lr: 0.0010\n",
      "Epoch 41/5000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 237.0540 - mae: 237.0540 - mse: 84984.6016 - val_loss: 327.1801 - val_mae: 327.1801 - val_mse: 135881.9219 - lr: 0.0010\n",
      "Epoch 42/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 113ms/step - loss: 198.2799 - mae: 198.2799 - mse: 59695.5312 - val_loss: 195.6655 - val_mae: 195.6655 - val_mse: 44330.6680 - lr: 0.0010\n",
      "Epoch 43/5000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 366.1038 - mae: 366.1038 - mse: 214295.2969 - val_loss: 508.0721 - val_mae: 508.0721 - val_mse: 290488.0312 - lr: 0.0010\n",
      "Epoch 44/5000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 461.3286 - mae: 461.3286 - mse: 268558.7500 - val_loss: 469.7678 - val_mae: 469.7678 - val_mse: 249540.2031 - lr: 0.0010\n",
      "Epoch 45/5000\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 424.2224 - mae: 424.2224 - mse: 239203.6875 - val_loss: 471.1277 - val_mae: 471.1277 - val_mse: 255555.2656 - lr: 0.0010\n",
      "Epoch 46/5000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 284.7104 - mae: 284.7104 - mse: 102776.6328 - val_loss: 212.2283 - val_mae: 212.2283 - val_mse: 78134.9062 - lr: 0.0010\n",
      "Epoch 47/5000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 185.0013 - mae: 185.0013 - mse: 58888.5938 - val_loss: 775.6465 - val_mae: 775.6465 - val_mse: 635250.0625 - lr: 0.0010\n",
      "Epoch 48/5000\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 662.9064 - mae: 662.9064 - mse: 611290.9375 - val_loss: 1384.4259 - val_mae: 1384.4259 - val_mse: 1951768.0000 - lr: 0.0010\n",
      "Epoch 49/5000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 1067.2866 - mae: 1067.2866 - mse: 1187602.7500 - val_loss: 293.4555 - val_mae: 293.4555 - val_mse: 116087.6641 - lr: 0.0010\n",
      "Epoch 50/5000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 272.6063 - mae: 272.6063 - mse: 110439.1406 - val_loss: 515.0889 - val_mae: 515.0889 - val_mse: 295465.9062 - lr: 0.0010\n",
      "Epoch 51/5000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 374.4682 - mae: 374.4682 - mse: 188123.1562 - val_loss: 509.2136 - val_mae: 509.2136 - val_mse: 287712.2812 - lr: 0.0010\n",
      "Epoch 52/5000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 365.3614 - mae: 365.3614 - mse: 174031.4531 - val_loss: 856.0368 - val_mae: 856.0368 - val_mse: 759460.3125 - lr: 0.0010\n",
      "Epoch 53/5000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 445.2212 - mae: 445.2212 - mse: 270751.5938 - val_loss: 182.6948 - val_mae: 182.6948 - val_mse: 43497.7070 - lr: 0.0010\n",
      "Epoch 54/5000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 339.7505 - mae: 339.7505 - mse: 155656.5156 - val_loss: 174.2778 - val_mae: 174.2778 - val_mse: 60062.1133 - lr: 0.0010\n",
      "Epoch 55/5000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 177.4147 - mae: 177.4147 - mse: 52600.3516 - val_loss: 392.5846 - val_mae: 392.5846 - val_mse: 182298.5781 - lr: 0.0010\n",
      "Epoch 56/5000\n",
      "2/2 [==============================] - 0s 245ms/step - loss: 231.6000 - mae: 231.6000 - mse: 71341.1250 - val_loss: 105.3692 - val_mae: 105.3692 - val_mse: 29185.5938 - lr: 0.0010\n",
      "Epoch 57/5000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 152.2460 - mae: 152.2460 - mse: 43898.6016 - val_loss: 184.8381 - val_mae: 184.8381 - val_mse: 37440.5430 - lr: 0.0010\n",
      "Epoch 58/5000\n",
      "2/2 [==============================] - 0s 250ms/step - loss: 263.0697 - mae: 263.0697 - mse: 92220.0781 - val_loss: 100.4456 - val_mae: 100.4456 - val_mse: 23181.2988 - lr: 0.0010\n",
      "Epoch 59/5000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 241.8474 - mae: 241.8474 - mse: 79615.6484 - val_loss: 767.7161 - val_mae: 767.7161 - val_mse: 613322.0625 - lr: 0.0010\n",
      "Epoch 60/5000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 456.5237 - mae: 456.5237 - mse: 260408.7188 - val_loss: 403.5533 - val_mae: 403.5533 - val_mse: 184411.2656 - lr: 0.0010\n",
      "Epoch 61/5000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 541.3569 - mae: 541.3569 - mse: 329358.5625 - val_loss: 306.9892 - val_mae: 306.9892 - val_mse: 120157.2266 - lr: 0.0010\n",
      "Epoch 62/5000\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 272.4561 - mae: 272.4561 - mse: 124360.6719 - val_loss: 464.5540 - val_mae: 464.5540 - val_mse: 240325.1250 - lr: 0.0010\n",
      "Epoch 63/5000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 303.9170 - mae: 303.9170 - mse: 131643.6094 - val_loss: 243.0061 - val_mae: 243.0061 - val_mse: 67985.6875 - lr: 0.0010\n",
      "Epoch 64/5000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 317.0691 - mae: 317.0691 - mse: 136825.9531 - val_loss: 481.1602 - val_mae: 481.1602 - val_mse: 259788.9531 - lr: 0.0010\n",
      "Epoch 65/5000\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 289.8623 - mae: 289.8623 - mse: 118573.5781 - val_loss: 132.4052 - val_mae: 132.4052 - val_mse: 40151.3945 - lr: 0.0010\n",
      "Epoch 66/5000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 184.8890 - mae: 184.8890 - mse: 54246.2617 - val_loss: 323.9387 - val_mae: 323.9387 - val_mse: 133713.1719 - lr: 0.0010\n",
      "Epoch 67/5000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 213.0785 - mae: 213.0785 - mse: 63005.4688 - val_loss: 163.6419 - val_mae: 163.6419 - val_mse: 52026.6758 - lr: 0.0010\n",
      "Epoch 68/5000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 214.7601 - mae: 214.7601 - mse: 74737.7812 - val_loss: 141.7487 - val_mae: 141.7487 - val_mse: 44199.2969 - lr: 0.0010\n",
      "Epoch 69/5000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 159.7618 - mae: 159.7618 - mse: 41086.8086 - val_loss: 468.2168 - val_mae: 468.2168 - val_mse: 248259.2969 - lr: 0.0010\n",
      "Epoch 70/5000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 264.0538 - mae: 264.0538 - mse: 100701.4922 - val_loss: 319.0193 - val_mae: 319.0193 - val_mse: 119693.7891 - lr: 0.0010\n",
      "Epoch 71/5000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 394.6458 - mae: 394.6458 - mse: 190889.0938 - val_loss: 419.4281 - val_mae: 419.4281 - val_mse: 201777.9531 - lr: 0.0010\n",
      "Epoch 72/5000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 255.0938 - mae: 255.0938 - mse: 102483.2188 - val_loss: 318.3248 - val_mae: 318.3248 - val_mse: 129026.7109 - lr: 0.0010\n",
      "Epoch 73/5000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 187.8575 - mae: 187.8575 - mse: 56103.2188 - val_loss: 314.4861 - val_mae: 314.4861 - val_mse: 127538.6641 - lr: 0.0010\n",
      "Epoch 74/5000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 155.5648 - mae: 155.5648 - mse: 43287.3398 - val_loss: 164.0291 - val_mae: 164.0291 - val_mse: 34263.9336 - lr: 0.0010\n",
      "Epoch 75/5000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 165.4955 - mae: 165.4955 - mse: 39833.3320 - val_loss: 268.2415 - val_mae: 268.2415 - val_mse: 101598.9453 - lr: 0.0010\n",
      "Epoch 76/5000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 234.0450 - mae: 234.0450 - mse: 74145.5781 - val_loss: 110.1058 - val_mae: 110.1058 - val_mse: 30550.8594 - lr: 0.0010\n",
      "Epoch 77/5000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 241.2659 - mae: 241.2659 - mse: 86225.3984 - val_loss: 205.7061 - val_mae: 205.7061 - val_mse: 68576.7812 - lr: 0.0010\n",
      "Epoch 78/5000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 197.8763 - mae: 197.8763 - mse: 63893.8516 - val_loss: 119.8039 - val_mae: 119.8039 - val_mse: 29810.1035 - lr: 0.0010\n",
      "Epoch 79/5000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 225.7281 - mae: 225.7281 - mse: 72371.8125 - val_loss: 332.9250 - val_mae: 332.9250 - val_mse: 139816.6719 - lr: 0.0010\n",
      "Epoch 80/5000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 310.6563 - mae: 310.6563 - mse: 133272.7031 - val_loss: 317.6064 - val_mae: 317.6064 - val_mse: 115188.3047 - lr: 0.0010\n",
      "Epoch 81/5000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 335.8560 - mae: 335.8560 - mse: 149896.6094 - val_loss: 383.3091 - val_mae: 383.3091 - val_mse: 177278.2031 - lr: 0.0010\n",
      "Epoch 82/5000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 290.5933 - mae: 290.5933 - mse: 113236.4375 - val_loss: 164.1331 - val_mae: 164.1331 - val_mse: 33320.6289 - lr: 0.0010\n",
      "Epoch 83/5000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 236.3181 - mae: 236.3180 - mse: 73933.2656 - val_loss: 241.5478 - val_mae: 241.5478 - val_mse: 83252.7891 - lr: 0.0010\n",
      "Epoch 84/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 116ms/step - loss: 243.1678 - mae: 243.1678 - mse: 101446.2031 - val_loss: 122.0233 - val_mae: 122.0233 - val_mse: 34799.6133 - lr: 0.0010\n",
      "Epoch 85/5000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 257.9082 - mae: 257.9082 - mse: 99248.4219 - val_loss: 272.7048 - val_mae: 272.7048 - val_mse: 99248.8203 - lr: 0.0010\n",
      "Epoch 86/5000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 304.5580 - mae: 304.5580 - mse: 146124.4531 - val_loss: 412.6646 - val_mae: 412.6646 - val_mse: 201715.5469 - lr: 0.0010\n",
      "Epoch 87/5000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 347.3273 - mae: 347.3273 - mse: 182745.8438 - val_loss: 673.1314 - val_mae: 673.1314 - val_mse: 485780.2812 - lr: 0.0010\n",
      "Epoch 88/5000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 403.5752 - mae: 403.5752 - mse: 214458.0625 - val_loss: 295.7567 - val_mae: 295.7567 - val_mse: 100625.7422 - lr: 0.0010\n",
      "Epoch 89/5000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 389.7897 - mae: 389.7897 - mse: 196264.4219 - val_loss: 424.3269 - val_mae: 424.3269 - val_mse: 203891.8281 - lr: 0.0010\n",
      "Epoch 90/5000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 243.6060 - mae: 243.6060 - mse: 89064.2188 - val_loss: 256.7289 - val_mae: 256.7289 - val_mse: 74793.8281 - lr: 0.0010\n",
      "Epoch 91/5000\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 294.3314 - mae: 294.3314 - mse: 118124.7188 - val_loss: 650.8179 - val_mae: 650.8179 - val_mse: 451687.3438 - lr: 0.0010\n",
      "Epoch 92/5000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 403.9283 - mae: 403.9283 - mse: 214902.9531 - val_loss: 721.9460 - val_mae: 721.9460 - val_mse: 547729.5000 - lr: 0.0010\n",
      "Epoch 93/5000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 733.2662 - mae: 733.2662 - mse: 568724.9375 - val_loss: 171.9919 - val_mae: 171.9919 - val_mse: 52459.9805 - lr: 0.0010\n",
      "Epoch 94/5000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 285.3249 - mae: 285.3249 - mse: 141721.5938 - val_loss: 613.5786 - val_mae: 613.5786 - val_mse: 400403.4688 - lr: 0.0010\n",
      "Epoch 95/5000\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 342.4873 - mae: 342.4873 - mse: 164533.7812 - val_loss: 129.8319 - val_mae: 129.8319 - val_mse: 27905.8379 - lr: 0.0010\n",
      "Epoch 96/5000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 245.3723 - mae: 245.3723 - mse: 91640.3438 - val_loss: 114.9877 - val_mae: 114.9877 - val_mse: 28850.9375 - lr: 0.0010\n",
      "Epoch 97/5000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 172.5016 - mae: 172.5016 - mse: 44050.8750 - val_loss: 540.0759 - val_mae: 540.0759 - val_mse: 319136.5938 - lr: 0.0010\n",
      "Epoch 98/5000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 300.9671 - mae: 300.9671 - mse: 122157.5469 - val_loss: 261.2503 - val_mae: 261.2503 - val_mse: 75142.4453 - lr: 0.0010\n",
      "Epoch 99/5000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 330.4777 - mae: 330.4777 - mse: 144243.2344 - val_loss: 357.2146 - val_mae: 357.2146 - val_mse: 156804.4688 - lr: 0.0010\n",
      "Epoch 100/5000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 349.1041 - mae: 349.1041 - mse: 172392.2031 - val_loss: 306.6842 - val_mae: 306.6842 - val_mse: 107726.0391 - lr: 0.0010\n",
      "Epoch 101/5000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 370.7817 - mae: 370.7817 - mse: 181844.3438 - val_loss: 406.2244 - val_mae: 406.2244 - val_mse: 196964.2500 - lr: 0.0010\n",
      "Epoch 102/5000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 204.8899 - mae: 204.8899 - mse: 66207.0469 - val_loss: 344.2422 - val_mae: 344.2422 - val_mse: 149398.0469 - lr: 0.0010\n",
      "Epoch 103/5000\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 181.8962 - mae: 181.8962 - mse: 53262.0781 - val_loss: 207.7374 - val_mae: 207.7374 - val_mse: 71297.2891 - lr: 0.0010\n",
      "Epoch 104/5000\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 130.1795 - mae: 130.1795 - mse: 30805.6445 - val_loss: 181.9827 - val_mae: 181.9827 - val_mse: 38180.3711 - lr: 0.0010\n",
      "Epoch 105/5000\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 267.8934 - mae: 267.8934 - mse: 102117.8984 - val_loss: 227.2664 - val_mae: 227.2664 - val_mse: 83611.5859 - lr: 0.0010\n",
      "Epoch 106/5000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 205.3380 - mae: 205.3380 - mse: 78462.2031 - val_loss: 126.1411 - val_mae: 126.1411 - val_mse: 38747.5820 - lr: 0.0010\n",
      "Epoch 107/5000\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 296.4868 - mae: 296.4868 - mse: 135773.6562 - val_loss: 543.0822 - val_mae: 543.0822 - val_mse: 323580.0938 - lr: 0.0010\n",
      "Epoch 108/5000\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 369.4915 - mae: 369.4915 - mse: 167596.5625 - val_loss: 212.2104 - val_mae: 212.2104 - val_mse: 48917.6445 - lr: 0.0010\n",
      "Epoch 109/5000\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 253.9198 - mae: 253.9198 - mse: 92770.3281 - val_loss: 281.1194 - val_mae: 281.1194 - val_mse: 105413.7891 - lr: 0.0010\n",
      "Epoch 110/5000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 164.4456 - mae: 164.4456 - mse: 50691.5508 - val_loss: 116.6358 - val_mae: 116.6358 - val_mse: 33113.3359 - lr: 0.0010\n",
      "Epoch 111/5000\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 213.7614 - mae: 213.7614 - mse: 63358.8867 - val_loss: 195.4689 - val_mae: 195.4689 - val_mse: 43812.8477 - lr: 0.0010\n",
      "Epoch 112/5000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 229.6166 - mae: 229.6166 - mse: 77259.7266 - val_loss: 110.5203 - val_mae: 110.5203 - val_mse: 29763.5762 - lr: 0.0010\n",
      "Epoch 113/5000\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 173.9368 - mae: 173.9368 - mse: 40464.2539 - val_loss: 379.7749 - val_mae: 379.7749 - val_mse: 167811.9375 - lr: 0.0010\n",
      "Epoch 114/5000\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 233.1129 - mae: 233.1129 - mse: 71103.5156 - val_loss: 116.4132 - val_mae: 116.4132 - val_mse: 29885.5527 - lr: 0.0010\n",
      "Epoch 115/5000\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 193.3595 - mae: 193.3595 - mse: 52238.3711 - val_loss: 116.5219 - val_mae: 116.5219 - val_mse: 32149.5781 - lr: 0.0010\n",
      "Epoch 116/5000\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 178.1314 - mae: 178.1314 - mse: 44048.3984 - val_loss: 523.1852 - val_mae: 523.1852 - val_mse: 297501.7188 - lr: 0.0010\n",
      "Epoch 117/5000\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 296.9566 - mae: 296.9566 - mse: 112207.2188 - val_loss: 331.9663 - val_mae: 331.9663 - val_mse: 124886.1484 - lr: 0.0010\n",
      "Epoch 118/5000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 442.4077 - mae: 442.4077 - mse: 225628.0938 - val_loss: 156.4176 - val_mae: 156.4176 - val_mse: 50225.1211 - lr: 0.0010\n",
      "Epoch 119/5000\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 222.9610 - mae: 222.9610 - mse: 90453.7266 - val_loss: 468.0715 - val_mae: 468.0715 - val_mse: 249786.4219 - lr: 0.0010\n",
      "Epoch 120/5000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 318.8431 - mae: 318.8431 - mse: 130974.0938 - val_loss: 240.2125 - val_mae: 240.2125 - val_mse: 61912.3555 - lr: 0.0010\n",
      "Epoch 121/5000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 265.5777 - mae: 265.5777 - mse: 94412.4219 - val_loss: 145.3668 - val_mae: 145.3668 - val_mse: 49024.6758 - lr: 0.0010\n",
      "Epoch 122/5000\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 184.8468 - mae: 184.8468 - mse: 54016.0664 - val_loss: 115.4361 - val_mae: 115.4361 - val_mse: 32222.6699 - lr: 0.0010\n",
      "Epoch 123/5000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 211.3768 - mae: 211.3768 - mse: 62458.1914 - val_loss: 121.4643 - val_mae: 121.4643 - val_mse: 38490.4570 - lr: 0.0010\n",
      "Epoch 124/5000\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 152.0152 - mae: 152.0152 - mse: 42152.6406 - val_loss: 378.0081 - val_mae: 378.0081 - val_mse: 169433.8438 - lr: 0.0010\n",
      "Epoch 125/5000\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 197.9975 - mae: 197.9975 - mse: 61852.0039 - val_loss: 165.4167 - val_mae: 165.4167 - val_mse: 52321.2812 - lr: 0.0010\n",
      "Epoch 126/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 122ms/step - loss: 167.3217 - mae: 167.3217 - mse: 53716.8867 - val_loss: 132.3182 - val_mae: 132.3182 - val_mse: 26382.1484 - lr: 0.0010\n",
      "Epoch 127/5000\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 136.9390 - mae: 136.9390 - mse: 28573.1445 - val_loss: 474.3162 - val_mae: 474.3162 - val_mse: 258207.2031 - lr: 0.0010\n",
      "Epoch 128/5000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 299.9478 - mae: 299.9478 - mse: 120851.7812 - val_loss: 314.1314 - val_mae: 314.1314 - val_mse: 115399.2500 - lr: 0.0010\n",
      "Epoch 129/5000\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 293.1681 - mae: 293.1681 - mse: 116964.0703 - val_loss: 395.5126 - val_mae: 395.5126 - val_mse: 184674.4375 - lr: 0.0010\n",
      "Epoch 130/5000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 287.5812 - mae: 287.5812 - mse: 106939.1797 - val_loss: 247.8268 - val_mae: 247.8268 - val_mse: 67566.3906 - lr: 0.0010\n",
      "Epoch 131/5000\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 235.3000 - mae: 235.3000 - mse: 75036.6719 - val_loss: 332.3547 - val_mae: 332.3547 - val_mse: 135225.4844 - lr: 0.0010\n",
      "Epoch 132/5000\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 148.4809 - mae: 148.4809 - mse: 37670.0664 - val_loss: 148.0522 - val_mae: 148.0522 - val_mse: 31093.5391 - lr: 0.0010\n",
      "Epoch 133/5000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 200.2719 - mae: 200.2719 - mse: 61753.9688 - val_loss: 363.7286 - val_mae: 363.7286 - val_mse: 161037.2500 - lr: 0.0010\n",
      "Epoch 134/5000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 198.2833 - mae: 198.2833 - mse: 58258.6016 - val_loss: 206.3820 - val_mae: 206.3820 - val_mse: 46814.2305 - lr: 0.0010\n",
      "Epoch 135/5000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 212.0211 - mae: 212.0211 - mse: 71439.9141 - val_loss: 129.6527 - val_mae: 129.6527 - val_mse: 45382.1719 - lr: 0.0010\n",
      "Epoch 136/5000\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 189.5040 - mae: 189.5040 - mse: 51404.6914 - val_loss: 111.9152 - val_mae: 111.9152 - val_mse: 32203.0215 - lr: 0.0010\n",
      "Epoch 137/5000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 206.4770 - mae: 206.4770 - mse: 76075.1562 - val_loss: 408.4747 - val_mae: 408.4747 - val_mse: 192845.2031 - lr: 0.0010\n",
      "Epoch 138/5000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 286.3974 - mae: 286.3973 - mse: 115552.9609 - val_loss: 186.1519 - val_mae: 186.1519 - val_mse: 40292.2539 - lr: 0.0010\n",
      "Epoch 139/5000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 280.4580 - mae: 280.4580 - mse: 109076.9297 - val_loss: 273.3827 - val_mae: 273.3827 - val_mse: 107999.6562 - lr: 0.0010\n",
      "Epoch 140/5000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 156.7677 - mae: 156.7677 - mse: 45029.6797 - val_loss: 261.9641 - val_mae: 261.9641 - val_mse: 99281.1875 - lr: 0.0010\n",
      "Epoch 141/5000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 137.3473 - mae: 137.3473 - mse: 34445.5156 - val_loss: 113.3359 - val_mae: 113.3359 - val_mse: 32288.1562 - lr: 0.0010\n",
      "Epoch 142/5000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 126.0723 - mae: 126.0723 - mse: 25721.7422 - val_loss: 342.0521 - val_mae: 342.0521 - val_mse: 144175.0469 - lr: 0.0010\n",
      "Epoch 143/5000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 193.1402 - mae: 193.1402 - mse: 53204.9805 - val_loss: 135.5790 - val_mae: 135.5790 - val_mse: 29697.1016 - lr: 0.0010\n",
      "Epoch 144/5000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 174.1036 - mae: 174.1036 - mse: 53521.5195 - val_loss: 129.6016 - val_mae: 129.6016 - val_mse: 32778.5977 - lr: 0.0010\n",
      "Epoch 145/5000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 192.3300 - mae: 192.3300 - mse: 51954.2188 - val_loss: 213.9832 - val_mae: 213.9832 - val_mse: 73079.2344 - lr: 0.0010\n",
      "Epoch 146/5000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 134.3316 - mae: 134.3316 - mse: 30212.9531 - val_loss: 138.3354 - val_mae: 138.3354 - val_mse: 27692.4922 - lr: 0.0010\n",
      "Epoch 147/5000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 214.3141 - mae: 214.3141 - mse: 62915.2461 - val_loss: 285.3734 - val_mae: 285.3734 - val_mse: 108232.9453 - lr: 0.0010\n",
      "Epoch 148/5000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 147.9075 - mae: 147.9075 - mse: 32929.3984 - val_loss: 290.1627 - val_mae: 290.1627 - val_mse: 97046.5391 - lr: 0.0010\n",
      "Epoch 149/5000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 194.8071 - mae: 194.8071 - mse: 56066.7305 - val_loss: 124.4909 - val_mae: 124.4909 - val_mse: 39189.8711 - lr: 0.0010\n",
      "Epoch 150/5000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 108.8753 - mae: 108.8753 - mse: 21683.0254 - val_loss: 269.2530 - val_mae: 269.2530 - val_mse: 103113.8672 - lr: 0.0010\n",
      "Epoch 151/5000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 173.5284 - mae: 173.5284 - mse: 49242.6133 - val_loss: 148.0891 - val_mae: 148.0891 - val_mse: 46915.6992 - lr: 0.0010\n",
      "Epoch 152/5000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 261.2355 - mae: 261.2355 - mse: 109467.0625 - val_loss: 464.0891 - val_mae: 464.0891 - val_mse: 249994.9531 - lr: 0.0010\n",
      "Epoch 153/5000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 336.9950 - mae: 336.9950 - mse: 136175.6875 - val_loss: 333.4013 - val_mae: 333.4013 - val_mse: 131617.5781 - lr: 0.0010\n",
      "Epoch 154/5000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 308.6619 - mae: 308.6619 - mse: 134830.5938 - val_loss: 592.0311 - val_mae: 592.0311 - val_mse: 372829.5000 - lr: 0.0010\n",
      "Epoch 155/5000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 305.6200 - mae: 305.6200 - mse: 126537.9609 - val_loss: 240.0578 - val_mae: 240.0578 - val_mse: 70635.7891 - lr: 0.0010\n",
      "Epoch 156/5000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 488.0736 - mae: 488.0736 - mse: 278777.2188 - val_loss: 412.8943 - val_mae: 412.8943 - val_mse: 195869.6094 - lr: 0.0010\n",
      "Epoch 157/5000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 220.9433 - mae: 220.9433 - mse: 75177.6250 - val_loss: 206.5609 - val_mae: 206.5609 - val_mse: 47055.8750 - lr: 0.0010\n",
      "Epoch 158/5000\n",
      "2/2 [==============================] - ETA: 0s - loss: 218.9753 - mae: 218.9753 - mse: 66807.4531\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 218.9753 - mae: 218.9753 - mse: 66807.4531 - val_loss: 534.0983 - val_mae: 534.0983 - val_mse: 314523.5938 - lr: 0.0010\n",
      "Epoch 159/5000\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 464.9003 - mae: 464.9003 - mse: 244408.8750 - val_loss: 409.8751 - val_mae: 409.8751 - val_mse: 197369.5781 - lr: 1.0000e-04\n",
      "Epoch 160/5000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 329.1995 - mae: 329.1995 - mse: 134340.8438 - val_loss: 115.1934 - val_mae: 115.1934 - val_mse: 32758.8359 - lr: 1.0000e-04\n",
      "Epoch 161/5000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 181.0996 - mae: 181.0996 - mse: 49525.1406 - val_loss: 296.2791 - val_mae: 296.2791 - val_mse: 100670.6875 - lr: 1.0000e-04\n",
      "Epoch 162/5000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 282.1649 - mae: 282.1649 - mse: 103482.4688 - val_loss: 290.8714 - val_mae: 290.8714 - val_mse: 96437.9609 - lr: 1.0000e-04\n",
      "Epoch 163/5000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 261.6231 - mae: 261.6231 - mse: 90081.7188 - val_loss: 134.8966 - val_mae: 134.8966 - val_mse: 30003.6973 - lr: 1.0000e-04\n",
      "Epoch 164/5000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 123.5327 - mae: 123.5327 - mse: 26151.6055 - val_loss: 215.2034 - val_mae: 215.2034 - val_mse: 75326.2266 - lr: 1.0000e-04\n",
      "Epoch 165/5000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 156.7969 - mae: 156.7969 - mse: 41817.5781 - val_loss: 305.3681 - val_mae: 305.3681 - val_mse: 121809.0000 - lr: 1.0000e-04\n",
      "Epoch 166/5000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 172.6566 - mae: 172.6566 - mse: 47701.0547 - val_loss: 222.5954 - val_mae: 222.5954 - val_mse: 77924.9297 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/5000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 104.8496 - mae: 104.8496 - mse: 22401.3301 - val_loss: 115.2359 - val_mae: 115.2359 - val_mse: 33441.7422 - lr: 1.0000e-04\n",
      "Epoch 168/5000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 143.7613 - mae: 143.7613 - mse: 29059.7832 - val_loss: 115.4897 - val_mae: 115.4897 - val_mse: 28762.0488 - lr: 1.0000e-04\n",
      "Epoch 169/5000\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 156.9179 - mae: 156.9179 - mse: 33031.1250 - val_loss: 114.5549 - val_mae: 114.5549 - val_mse: 33669.2383 - lr: 1.0000e-04\n",
      "Epoch 170/5000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 102.6421 - mae: 102.6421 - mse: 17018.3457 - val_loss: 188.8533 - val_mae: 188.8533 - val_mse: 62941.8789 - lr: 1.0000e-04\n",
      "Epoch 171/5000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 116.8224 - mae: 116.8224 - mse: 25035.8145 - val_loss: 201.0859 - val_mae: 201.0859 - val_mse: 68222.1250 - lr: 1.0000e-04\n",
      "Epoch 172/5000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 114.2023 - mae: 114.2023 - mse: 24642.4355 - val_loss: 126.9539 - val_mae: 126.9539 - val_mse: 41284.0195 - lr: 1.0000e-04\n",
      "Epoch 173/5000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 92.4008 - mae: 92.4008 - mse: 14873.5723 - val_loss: 114.0456 - val_mae: 114.0456 - val_mse: 30612.2598 - lr: 1.0000e-04\n",
      "Epoch 174/5000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 103.7492 - mae: 103.7492 - mse: 16777.8145 - val_loss: 117.6596 - val_mae: 117.6596 - val_mse: 35436.9297 - lr: 1.0000e-04\n",
      "Epoch 175/5000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 86.6390 - mae: 86.6390 - mse: 14473.4473 - val_loss: 169.8241 - val_mae: 169.8241 - val_mse: 56141.6250 - lr: 1.0000e-04\n",
      "Epoch 176/5000\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 96.8005 - mae: 96.8005 - mse: 18642.9570 - val_loss: 184.5919 - val_mae: 184.5919 - val_mse: 61372.6445 - lr: 1.0000e-04\n",
      "Epoch 177/5000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 91.5789 - mae: 91.5789 - mse: 17560.2695 - val_loss: 123.4591 - val_mae: 123.4591 - val_mse: 39959.0781 - lr: 1.0000e-04\n",
      "Epoch 178/5000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 78.4536 - mae: 78.4536 - mse: 12374.6699 - val_loss: 115.9181 - val_mae: 115.9181 - val_mse: 33753.4688 - lr: 1.0000e-04\n",
      "Epoch 179/5000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 84.9886 - mae: 84.9886 - mse: 12812.7715 - val_loss: 125.6080 - val_mae: 125.6080 - val_mse: 40438.4883 - lr: 1.0000e-04\n",
      "Epoch 180/5000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 74.4213 - mae: 74.4213 - mse: 11848.1299 - val_loss: 187.8373 - val_mae: 187.8373 - val_mse: 62320.4570 - lr: 1.0000e-04\n",
      "Epoch 181/5000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 83.3654 - mae: 83.3654 - mse: 16496.7793 - val_loss: 175.3193 - val_mae: 175.3193 - val_mse: 57659.3008 - lr: 1.0000e-04\n",
      "Epoch 182/5000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 70.5908 - mae: 70.5908 - mse: 13182.9434 - val_loss: 134.6115 - val_mae: 134.6115 - val_mse: 43892.3945 - lr: 1.0000e-04\n",
      "Epoch 183/5000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 77.1430 - mae: 77.1430 - mse: 11780.7197 - val_loss: 127.7978 - val_mae: 127.7978 - val_mse: 40365.9492 - lr: 1.0000e-04\n",
      "Epoch 184/5000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 75.3283 - mae: 75.3283 - mse: 11668.7471 - val_loss: 185.1991 - val_mae: 185.1991 - val_mse: 60680.2812 - lr: 1.0000e-04\n",
      "Epoch 185/5000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 80.3327 - mae: 80.3327 - mse: 15621.5596 - val_loss: 191.1108 - val_mae: 191.1108 - val_mse: 62973.9688 - lr: 1.0000e-04\n",
      "Epoch 186/5000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 73.9910 - mae: 73.9910 - mse: 12783.3613 - val_loss: 123.4953 - val_mae: 123.4953 - val_mse: 38054.8398 - lr: 1.0000e-04\n",
      "Epoch 187/5000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 67.8961 - mae: 67.8961 - mse: 9805.9561 - val_loss: 129.1593 - val_mae: 129.1593 - val_mse: 40839.4023 - lr: 1.0000e-04\n",
      "Epoch 188/5000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 60.0608 - mae: 60.0608 - mse: 9830.7617 - val_loss: 146.8223 - val_mae: 146.8223 - val_mse: 48474.1992 - lr: 1.0000e-04\n",
      "Epoch 189/5000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 64.0841 - mae: 64.0841 - mse: 10851.2695 - val_loss: 138.5950 - val_mae: 138.5950 - val_mse: 45100.1719 - lr: 1.0000e-04\n",
      "Epoch 190/5000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 57.7100 - mae: 57.7100 - mse: 9368.1338 - val_loss: 134.8032 - val_mae: 134.8032 - val_mse: 43604.7188 - lr: 1.0000e-04\n",
      "Epoch 191/5000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 58.4005 - mae: 58.4005 - mse: 9225.2334 - val_loss: 171.5709 - val_mae: 171.5709 - val_mse: 55697.9062 - lr: 1.0000e-04\n",
      "Epoch 192/5000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 57.6926 - mae: 57.6926 - mse: 10258.9209 - val_loss: 166.4539 - val_mae: 166.4539 - val_mse: 53794.9961 - lr: 1.0000e-04\n",
      "Epoch 193/5000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 52.9697 - mae: 52.9697 - mse: 9159.9180 - val_loss: 129.6696 - val_mae: 129.6696 - val_mse: 41211.0430 - lr: 1.0000e-04\n",
      "Epoch 194/5000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 57.0310 - mae: 57.0310 - mse: 8242.9346 - val_loss: 140.5208 - val_mae: 140.5208 - val_mse: 45817.7969 - lr: 1.0000e-04\n",
      "Epoch 195/5000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 50.3684 - mae: 50.3684 - mse: 8736.8359 - val_loss: 148.9404 - val_mae: 148.9404 - val_mse: 48595.3594 - lr: 1.0000e-04\n",
      "Epoch 196/5000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 51.5965 - mae: 51.5965 - mse: 8808.3848 - val_loss: 127.1532 - val_mae: 127.1532 - val_mse: 40898.7188 - lr: 1.0000e-04\n",
      "Epoch 197/5000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 48.3643 - mae: 48.3643 - mse: 7746.0537 - val_loss: 132.7597 - val_mae: 132.7597 - val_mse: 42999.4336 - lr: 1.0000e-04\n",
      "Epoch 198/5000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 47.9490 - mae: 47.9490 - mse: 7899.4199 - val_loss: 153.3188 - val_mae: 153.3188 - val_mse: 49767.8320 - lr: 1.0000e-04\n",
      "Epoch 199/5000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 46.5602 - mae: 46.5602 - mse: 7808.5850 - val_loss: 141.7222 - val_mae: 141.7222 - val_mse: 46377.9688 - lr: 1.0000e-04\n",
      "Epoch 200/5000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 42.9547 - mae: 42.9547 - mse: 7368.3794 - val_loss: 138.5727 - val_mae: 138.5727 - val_mse: 44855.5195 - lr: 1.0000e-04\n",
      "Epoch 201/5000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 42.4011 - mae: 42.4011 - mse: 7226.8857 - val_loss: 137.0579 - val_mae: 137.0579 - val_mse: 44285.6562 - lr: 1.0000e-04\n",
      "Epoch 202/5000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 41.8671 - mae: 41.8671 - mse: 7350.0327 - val_loss: 135.6786 - val_mae: 135.6786 - val_mse: 43860.5430 - lr: 1.0000e-04\n",
      "Epoch 203/5000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 40.8585 - mae: 40.8585 - mse: 6721.5640 - val_loss: 157.1528 - val_mae: 157.1528 - val_mse: 50667.8867 - lr: 1.0000e-04\n",
      "Epoch 204/5000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 42.7256 - mae: 42.7256 - mse: 7582.1851 - val_loss: 131.3625 - val_mae: 131.3625 - val_mse: 42241.5938 - lr: 1.0000e-04\n",
      "Epoch 205/5000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 41.6658 - mae: 41.6658 - mse: 6459.3062 - val_loss: 147.7467 - val_mae: 147.7467 - val_mse: 48135.6914 - lr: 1.0000e-04\n",
      "Epoch 206/5000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 38.3223 - mae: 38.3223 - mse: 6641.4087 - val_loss: 138.4228 - val_mae: 138.4228 - val_mse: 44569.3750 - lr: 1.0000e-04\n",
      "Epoch 207/5000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 42.1120 - mae: 42.1120 - mse: 6044.0518 - val_loss: 162.0431 - val_mae: 162.0431 - val_mse: 52308.6602 - lr: 1.0000e-04\n",
      "Epoch 208/5000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 38.8551 - mae: 38.8551 - mse: 6591.3726 - val_loss: 138.8529 - val_mae: 138.8529 - val_mse: 44788.2031 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209/5000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 41.1248 - mae: 41.1248 - mse: 6689.3149 - val_loss: 147.7434 - val_mae: 147.7434 - val_mse: 48084.1719 - lr: 1.0000e-04\n",
      "Epoch 210/5000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 36.7305 - mae: 36.7305 - mse: 6701.0796 - val_loss: 147.8553 - val_mae: 147.8553 - val_mse: 47835.7852 - lr: 1.0000e-04\n",
      "Epoch 211/5000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 41.2244 - mae: 41.2244 - mse: 5858.8662 - val_loss: 135.2471 - val_mae: 135.2471 - val_mse: 43411.6250 - lr: 1.0000e-04\n",
      "Epoch 212/5000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 41.2661 - mae: 41.2661 - mse: 5489.9448 - val_loss: 143.5891 - val_mae: 143.5891 - val_mse: 46962.2617 - lr: 1.0000e-04\n",
      "Epoch 213/5000\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 37.4427 - mae: 37.4427 - mse: 6345.6226 - val_loss: 157.8035 - val_mae: 157.8035 - val_mse: 51254.3594 - lr: 1.0000e-04\n",
      "Epoch 214/5000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 39.5421 - mae: 39.5421 - mse: 6713.7163 - val_loss: 132.3252 - val_mae: 132.3252 - val_mse: 42461.7383 - lr: 1.0000e-04\n",
      "Epoch 215/5000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 37.5271 - mae: 37.5271 - mse: 5287.8149 - val_loss: 175.0992 - val_mae: 175.0992 - val_mse: 56431.3633 - lr: 1.0000e-04\n",
      "Epoch 216/5000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 46.4118 - mae: 46.4118 - mse: 6826.9390 - val_loss: 129.0220 - val_mae: 129.0220 - val_mse: 39799.4414 - lr: 1.0000e-04\n",
      "Epoch 217/5000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 48.1195 - mae: 48.1195 - mse: 5343.9502 - val_loss: 139.8337 - val_mae: 139.8337 - val_mse: 44089.2656 - lr: 1.0000e-04\n",
      "Epoch 218/5000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 40.3698 - mae: 40.3698 - mse: 5778.1099 - val_loss: 185.8918 - val_mae: 185.8918 - val_mse: 60316.7188 - lr: 1.0000e-04\n",
      "Epoch 219/5000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 44.7812 - mae: 44.7812 - mse: 6693.5605 - val_loss: 132.1589 - val_mae: 132.1589 - val_mse: 41363.3516 - lr: 1.0000e-04\n",
      "Epoch 220/5000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 43.9382 - mae: 43.9382 - mse: 5996.4712 - val_loss: 175.7639 - val_mae: 175.7639 - val_mse: 56504.3438 - lr: 1.0000e-04\n",
      "Epoch 221/5000\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 50.8838 - mae: 50.8838 - mse: 8026.9873 - val_loss: 127.0763 - val_mae: 127.0763 - val_mse: 38052.5938 - lr: 1.0000e-04\n",
      "Epoch 222/5000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 42.7706 - mae: 42.7706 - mse: 4910.1064 - val_loss: 136.0977 - val_mae: 136.0977 - val_mse: 42622.1719 - lr: 1.0000e-04\n",
      "Epoch 223/5000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 47.5699 - mae: 47.5699 - mse: 6224.0981 - val_loss: 151.5008 - val_mae: 151.5008 - val_mse: 48224.8633 - lr: 1.0000e-04\n",
      "Epoch 224/5000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 38.3426 - mae: 38.3426 - mse: 5345.3120 - val_loss: 124.4015 - val_mae: 124.4015 - val_mse: 38277.9805 - lr: 1.0000e-04\n",
      "Epoch 225/5000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 38.0214 - mae: 38.0214 - mse: 5093.1470 - val_loss: 154.3586 - val_mae: 154.3586 - val_mse: 49384.7812 - lr: 1.0000e-04\n",
      "Epoch 226/5000\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 38.4402 - mae: 38.4402 - mse: 6600.3101 - val_loss: 158.1762 - val_mae: 158.1762 - val_mse: 50579.7383 - lr: 1.0000e-04\n",
      "Epoch 227/5000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 33.7800 - mae: 33.7800 - mse: 5212.9663 - val_loss: 172.6383 - val_mae: 172.6383 - val_mse: 55130.7070 - lr: 1.0000e-04\n",
      "Epoch 228/5000\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 38.4290 - mae: 38.4290 - mse: 5215.2334 - val_loss: 121.9308 - val_mae: 121.9308 - val_mse: 35299.6445 - lr: 1.0000e-04\n",
      "Epoch 229/5000\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 45.7360 - mae: 45.7360 - mse: 4540.4062 - val_loss: 127.8019 - val_mae: 127.8019 - val_mse: 37801.1992 - lr: 1.0000e-04\n",
      "Epoch 230/5000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 41.3883 - mae: 41.3883 - mse: 5431.0469 - val_loss: 134.7104 - val_mae: 134.7104 - val_mse: 41690.7227 - lr: 1.0000e-04\n",
      "Epoch 231/5000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 38.8989 - mae: 38.8989 - mse: 5314.2754 - val_loss: 138.0111 - val_mae: 138.0111 - val_mse: 43601.1719 - lr: 1.0000e-04\n",
      "Epoch 232/5000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 31.6658 - mae: 31.6658 - mse: 4822.7593 - val_loss: 150.3377 - val_mae: 150.3377 - val_mse: 48575.9805 - lr: 1.0000e-04\n",
      "Epoch 233/5000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 35.8664 - mae: 35.8664 - mse: 4884.3643 - val_loss: 124.7572 - val_mae: 124.7572 - val_mse: 38984.0508 - lr: 1.0000e-04\n",
      "Epoch 234/5000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 34.8267 - mae: 34.8267 - mse: 4528.9302 - val_loss: 133.7874 - val_mae: 133.7874 - val_mse: 43030.3008 - lr: 1.0000e-04\n",
      "Epoch 235/5000\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 32.9082 - mae: 32.9082 - mse: 4185.6133 - val_loss: 123.8551 - val_mae: 123.8551 - val_mse: 36175.4062 - lr: 1.0000e-04\n",
      "Epoch 236/5000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 36.3921 - mae: 36.3921 - mse: 4202.8677 - val_loss: 144.8905 - val_mae: 144.8905 - val_mse: 46399.1562 - lr: 1.0000e-04\n",
      "Epoch 237/5000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 25.8559 - mae: 25.8559 - mse: 4099.5605 - val_loss: 140.6291 - val_mae: 140.6291 - val_mse: 45043.3320 - lr: 1.0000e-04\n",
      "Epoch 238/5000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 25.6243 - mae: 25.6243 - mse: 3995.9109 - val_loss: 123.2923 - val_mae: 123.2923 - val_mse: 38669.6406 - lr: 1.0000e-04\n",
      "Epoch 239/5000\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 27.5799 - mae: 27.5799 - mse: 3864.8840 - val_loss: 139.7596 - val_mae: 139.7596 - val_mse: 45017.6719 - lr: 1.0000e-04\n",
      "Epoch 240/5000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 38.7188 - mae: 38.7188 - mse: 4831.3330 - val_loss: 117.9133 - val_mae: 117.9133 - val_mse: 34127.2969 - lr: 1.0000e-04\n",
      "Epoch 241/5000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 46.0340 - mae: 46.0340 - mse: 4014.3018 - val_loss: 160.3122 - val_mae: 160.3122 - val_mse: 50999.6562 - lr: 1.0000e-04\n",
      "Epoch 242/5000\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 45.1192 - mae: 45.1192 - mse: 6178.1094 - val_loss: 168.1511 - val_mae: 168.1511 - val_mse: 53699.6680 - lr: 1.0000e-04\n",
      "Epoch 243/5000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 44.4366 - mae: 44.4366 - mse: 5570.8691 - val_loss: 117.0935 - val_mae: 117.0935 - val_mse: 31433.7031 - lr: 1.0000e-04\n",
      "Epoch 244/5000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 52.2198 - mae: 52.2198 - mse: 4644.4302 - val_loss: 143.1914 - val_mae: 143.1914 - val_mse: 44975.5195 - lr: 1.0000e-04\n",
      "Epoch 245/5000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 36.9924 - mae: 36.9924 - mse: 4713.7241 - val_loss: 119.3918 - val_mae: 119.3918 - val_mse: 31893.6621 - lr: 1.0000e-04\n",
      "Epoch 246/5000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 35.8813 - mae: 35.8813 - mse: 3265.0667 - val_loss: 132.4637 - val_mae: 132.4637 - val_mse: 41518.7148 - lr: 1.0000e-04\n",
      "Epoch 247/5000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 36.8557 - mae: 36.8557 - mse: 4096.6782 - val_loss: 129.8885 - val_mae: 129.8885 - val_mse: 40568.7539 - lr: 1.0000e-04\n",
      "Epoch 248/5000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 30.2152 - mae: 30.2152 - mse: 3315.6340 - val_loss: 148.1423 - val_mae: 148.1423 - val_mse: 47730.0469 - lr: 1.0000e-04\n",
      "Epoch 249/5000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 29.5886 - mae: 29.5886 - mse: 4205.1089 - val_loss: 121.2137 - val_mae: 121.2137 - val_mse: 33854.0859 - lr: 1.0000e-04\n",
      "Epoch 250/5000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 29.5739 - mae: 29.5739 - mse: 3278.8291 - val_loss: 127.4821 - val_mae: 127.4821 - val_mse: 37311.1758 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 251/5000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 38.9985 - mae: 38.9985 - mse: 3807.1023 - val_loss: 123.0228 - val_mae: 123.0228 - val_mse: 35436.1289 - lr: 1.0000e-04\n",
      "Epoch 252/5000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 36.7699 - mae: 36.7699 - mse: 3042.0056 - val_loss: 132.6228 - val_mae: 132.6228 - val_mse: 40349.6211 - lr: 1.0000e-04\n",
      "Epoch 253/5000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 25.5729 - mae: 25.5729 - mse: 2996.6895 - val_loss: 140.6244 - val_mae: 140.6244 - val_mse: 43882.2188 - lr: 1.0000e-04\n",
      "Epoch 254/5000\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 29.4613 - mae: 29.4613 - mse: 3534.0469 - val_loss: 123.1637 - val_mae: 123.1637 - val_mse: 37168.6836 - lr: 1.0000e-04\n",
      "Epoch 255/5000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 35.1016 - mae: 35.1016 - mse: 3144.4360 - val_loss: 142.4595 - val_mae: 142.4595 - val_mse: 45882.9570 - lr: 1.0000e-04\n",
      "Epoch 256/5000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 35.1232 - mae: 35.1232 - mse: 3479.0190 - val_loss: 119.7054 - val_mae: 119.7054 - val_mse: 33597.4414 - lr: 1.0000e-04\n",
      "Epoch 257/5000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 38.0223 - mae: 38.0223 - mse: 4249.2183 - val_loss: 165.0331 - val_mae: 165.0331 - val_mse: 53017.3867 - lr: 1.0000e-04\n",
      "Epoch 258/5000\n",
      "2/2 [==============================] - ETA: 0s - loss: 39.5573 - mae: 39.5573 - mse: 5321.6079\n",
      "Epoch 00258: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "2/2 [==============================] - 0s 181ms/step - loss: 39.5573 - mae: 39.5573 - mse: 5321.6079 - val_loss: 119.5683 - val_mae: 119.5683 - val_mse: 33511.7148 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "block1 = blocks(number_neurons,\n",
    "                 number_layers,\n",
    "                 input_size,\n",
    "                 output_size,\n",
    "                 theta_size)\n",
    "stack_inputs = tf.keras.layers.Input(shape = (input_size))\n",
    "backcasts,forecasts = block1(stack_inputs)\n",
    "residual = tf.keras.layers.subtract([stack_inputs,backcasts])\n",
    "for i,_ in enumerate(range(number_stacks-1)):\n",
    "    backcasts, block_forecasts = blocks(number_neurons,\n",
    "                                 number_layers,\n",
    "                                 input_size,\n",
    "                                 output_size,\n",
    "                                 theta_size)(residual)\n",
    "    residual = tf.keras.layers.subtract([residual, backcasts])\n",
    "    forecasts = tf.keras.layers.add([forecasts, block_forecasts])\n",
    "model_nbeats = tf.keras.models.Model(inputs = stack_inputs, outputs = forecasts)\n",
    "# compiling the model\n",
    "model_nbeats.compile(loss=\"mae\",\n",
    "                optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "                metrics=[\"mae\", \"mse\"])\n",
    "# fitting the model\n",
    "history = model_nbeats.fit(final_x_zeros[:k],final_y_zeros[:k],\n",
    "            epochs = epochs,\n",
    "            validation_data=(final_x_zeros[k:],final_y_zeros[k:]), \n",
    "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", \n",
    "                                                        patience=200, \n",
    "                                                        restore_best_weights=True),\n",
    "                      tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", \n",
    "                                                           patience=100, \n",
    "                                                           verbose=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047b4ee6",
   "metadata": {},
   "source": [
    "# EVALUATING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94fba28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step - loss: 100.4456 - mae: 100.4456 - mse: 23181.2988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[100.445556640625, 100.445556640625, 23181.298828125]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nbeats.evaluate(final_x_zeros[k:], final_y_zeros[k:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa89b785",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as theta_layer_call_fn, theta_layer_call_and_return_conditional_losses, theta_layer_call_fn, theta_layer_call_and_return_conditional_losses, theta_layer_call_fn while saving (showing 5 of 750). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: nbeats_maruti suzuki\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: nbeats_maruti suzuki\\assets\n",
      "c:\\users\\harshvardhan bhosale\\onedrive\\desktop\\webscrapping\\ws_env\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "c:\\users\\harshvardhan bhosale\\onedrive\\desktop\\webscrapping\\ws_env\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    }
   ],
   "source": [
    "model_nbeats.save(\"nbeats_maruti suzuki\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39e18215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_x_zeros[k:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc765287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2be3f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c95a807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba9b5f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f287c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef70d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a17e4a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2ff854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edbda8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb4c3da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297a52d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03d9390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d729e780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2ed9c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e0654b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce22b7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4cc4ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609b5b01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ws_env",
   "language": "python",
   "name": "ws_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
